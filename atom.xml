<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SnailTyan</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://noahsnail.com/"/>
  <updated>2018-07-16T08:26:51.000Z</updated>
  <id>http://noahsnail.com/</id>
  
  <author>
    <name>Tyan</name>
    <email>Tyan.Liu.Git@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Leetcode 507. Perfect Number</title>
    <link href="http://noahsnail.com/2018/07/16/2018-07-16-Leetcode%20507.%20Perfect%20Number/"/>
    <id>http://noahsnail.com/2018/07/16/2018-07-16-Leetcode 507. Perfect Number/</id>
    <published>2018-07-16T08:26:45.000Z</published>
    <updated>2018-07-16T08:26:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-1cafd8f71d156934.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Perfect Number"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">checkPerfectNumber</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span>(num == <span class="number">1</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> sum = <span class="number">1</span>;</div><div class="line">        <span class="keyword">int</span> root = <span class="built_in">sqrt</span>(num) + <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; root; i++) &#123;</div><div class="line">            <span class="keyword">if</span>(num % i == <span class="number">0</span>) &#123;</div><div class="line">                sum += i;</div><div class="line">                <span class="keyword">if</span>(i * i != num) &#123;</div><div class="line">                    sum += num / i;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> sum == num;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/perfect-number/description/" target="_blank" rel="external">https://leetcode.com/problems/perfect-number/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 507. Perfect Number
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 101. Symmetric Tree</title>
    <link href="http://noahsnail.com/2018/07/16/2018-07-16-Leetcode%20101.%20Symmetric%20Tree/"/>
    <id>http://noahsnail.com/2018/07/16/2018-07-16-Leetcode 101. Symmetric Tree/</id>
    <published>2018-07-16T08:26:14.000Z</published>
    <updated>2018-07-16T08:26:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-fc873a6d82ec7d81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Symmetric Tree"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><ul>
<li>Recursive</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Definition for a binary tree node.</div><div class="line"> * struct TreeNode &#123;</div><div class="line"> *     int val;</div><div class="line"> *     TreeNode *left;</div><div class="line"> *     TreeNode *right;</div><div class="line"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;</div><div class="line"> * &#125;;</div><div class="line"> */</div><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isSymmetric</span><span class="params">(TreeNode* root)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> isMirror(root-&gt;left, root-&gt;right);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isMirror</span><span class="params">(TreeNode* left, TreeNode* right)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span>(left == <span class="literal">NULL</span> &amp;&amp; right == <span class="literal">NULL</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span>(left == <span class="literal">NULL</span> || right == <span class="literal">NULL</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> left-&gt;val == right-&gt;val &amp;&amp; isMirror(left-&gt;left, right-&gt;right) &amp;&amp; isMirror(left-&gt;right, right-&gt;left);</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>Iterative<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Definition for a binary tree node.</div><div class="line"> * struct TreeNode &#123;</div><div class="line"> *     int val;</div><div class="line"> *     TreeNode *left;</div><div class="line"> *     TreeNode *right;</div><div class="line"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;</div><div class="line"> * &#125;;</div><div class="line"> */</div><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isSymmetric</span><span class="params">(TreeNode* root)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span>(root == <span class="literal">NULL</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">queue</span>&lt;TreeNode*&gt; nodes;</div><div class="line">        nodes.push(root);</div><div class="line">        nodes.push(root);</div><div class="line">        <span class="keyword">while</span>(!nodes.empty()) &#123;</div><div class="line">            TreeNode* left = nodes.front();</div><div class="line">            nodes.pop();</div><div class="line">            TreeNode* right = nodes.front();</div><div class="line">            nodes.pop();</div><div class="line">            <span class="keyword">if</span>(left == <span class="literal">NULL</span> &amp;&amp; right == <span class="literal">NULL</span>) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(left == <span class="literal">NULL</span> || right == <span class="literal">NULL</span>) &#123;</div><div class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(left-&gt;val == right-&gt;val) &#123;</div><div class="line">                nodes.push(left-&gt;left);</div><div class="line">                nodes.push(right-&gt;right);</div><div class="line">                nodes.push(left-&gt;right);</div><div class="line">                nodes.push(right-&gt;left);</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/symmetric-tree/description/" target="_blank" rel="external">https://leetcode.com/problems/symmetric-tree/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 101. Symmetric Tree
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 66. Plus One</title>
    <link href="http://noahsnail.com/2018/07/16/2018-07-13-Leetcode%2066.%20Plus%20One/"/>
    <id>http://noahsnail.com/2018/07/16/2018-07-13-Leetcode 66. Plus One/</id>
    <published>2018-07-16T08:25:36.000Z</published>
    <updated>2018-07-16T08:25:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-b47a7e72a2dfc984.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Plus One"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; plusOne(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; digits) &#123;</div><div class="line">        <span class="keyword">int</span> length = digits.size();</div><div class="line">        <span class="keyword">int</span> index = length - <span class="number">1</span>;</div><div class="line">        <span class="keyword">while</span>(index &gt;= <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">int</span> sum = digits[index] + <span class="number">1</span>;</div><div class="line">            <span class="keyword">if</span>(sum == <span class="number">10</span>) &#123;</div><div class="line">                digits[index] = <span class="number">0</span>;</div><div class="line">                index--;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                digits[index] = sum;</div><div class="line">                <span class="keyword">return</span> digits;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        digits.insert(digits.begin(), <span class="number">1</span>);</div><div class="line">        <span class="keyword">return</span> digits;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/plus-one/description/" target="_blank" rel="external">https://leetcode.com/problems/plus-one/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 66. Plus One
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 15. 3Sum</title>
    <link href="http://noahsnail.com/2018/07/13/2018-07-13-Leetcode%2015.%203Sum/"/>
    <id>http://noahsnail.com/2018/07/13/2018-07-13-Leetcode 15. 3Sum/</id>
    <published>2018-07-13T05:57:19.000Z</published>
    <updated>2018-07-13T06:15:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-7a769bd3ef4b11cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="3Sum"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; threeSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</div><div class="line">        sort(nums.begin(), nums.end());</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; result;</div><div class="line">        <span class="keyword">int</span> length = nums.size();</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length - <span class="number">1</span>; i++) &#123;</div><div class="line">            <span class="keyword">if</span>(i != <span class="number">0</span> &amp;&amp; nums[i] == nums[i - <span class="number">1</span>]) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> target = <span class="number">0</span> - nums[i];</div><div class="line">            <span class="keyword">int</span> left = i + <span class="number">1</span>;</div><div class="line">            <span class="keyword">int</span> right = length - <span class="number">1</span>;</div><div class="line">            <span class="keyword">while</span>(left &lt; right) &#123;</div><div class="line">                <span class="keyword">if</span>(left != i + <span class="number">1</span> &amp;&amp; nums[left] == nums[left - <span class="number">1</span>]) &#123;</div><div class="line">                    left++;</div><div class="line">                    <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span>(right != length - <span class="number">1</span> &amp;&amp; nums[right] == nums[right + <span class="number">1</span>]) &#123;</div><div class="line">                    right--;</div><div class="line">                    <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">int</span> sum = nums[left] + nums[right];</div><div class="line">                <span class="keyword">if</span>(sum == target) &#123;</div><div class="line">                    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</div><div class="line">                    temp.push_back(nums[i]);</div><div class="line">                    temp.push_back(nums[left]);</div><div class="line">                    temp.push_back(nums[right]);</div><div class="line">                    result.push_back(temp);</div><div class="line">                    left++;</div><div class="line">                    right--;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(sum &lt; target) &#123;</div><div class="line">                    left++;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> &#123;</div><div class="line">                    right--;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/3sum/description/" target="_blank" rel="external">https://leetcode.com/problems/3sum/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 15. 3Sum
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 45. Jump Game II</title>
    <link href="http://noahsnail.com/2018/07/12/2018-07-12-Leetcode%2045.%20Jump%20Game%20II/"/>
    <id>http://noahsnail.com/2018/07/12/2018-07-12-Leetcode 45. Jump Game II/</id>
    <published>2018-07-12T10:20:39.000Z</published>
    <updated>2018-07-13T06:19:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-ca4a024346121cfd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Jump Game II"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">jump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> current = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span>(current &lt; nums.size() - <span class="number">1</span>) &#123;</div><div class="line">            count++;</div><div class="line">            <span class="keyword">if</span>(current + nums[current] &gt;= nums.size() - <span class="number">1</span>) &#123;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> distance = <span class="number">0</span>;</div><div class="line">            <span class="keyword">int</span> index = current + <span class="number">1</span>;</div><div class="line">            <span class="keyword">int</span> begin = current + <span class="number">1</span>;</div><div class="line">            <span class="keyword">int</span> end = current + nums[current];</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = begin; i &lt;= end; i++) &#123;</div><div class="line">                <span class="keyword">if</span>(nums[i] + i &gt; distance) &#123;</div><div class="line">                    distance = nums[i] + i;</div><div class="line">                    index = i;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            current = index;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> count;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/jump-game-ii/description/" target="_blank" rel="external">https://leetcode.com/problems/jump-game-ii/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 45. Jump Game II
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 59. Spiral Matrix II</title>
    <link href="http://noahsnail.com/2018/07/12/2018-07-12-Leetcode%2059.%20Spiral%20Matrix%20II/"/>
    <id>http://noahsnail.com/2018/07/12/2018-07-12-Leetcode 59. Spiral Matrix II/</id>
    <published>2018-07-12T03:27:41.000Z</published>
    <updated>2018-07-12T03:30:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-371a308b363668c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Spiral Matrix II"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; generateMatrix(<span class="keyword">int</span> n) &#123;</div><div class="line">        <span class="keyword">int</span> total = n * n;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; matrix;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; row(n, <span class="number">0</span>);</div><div class="line">            matrix.push_back(row);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, count = <span class="number">0</span>; count &lt; total; i++, j++) &#123;</div><div class="line">            <span class="comment">// top</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = j; k &lt; n - j; k++) &#123;</div><div class="line">                matrix[i][k] = ++count;</div><div class="line">            &#125;</div><div class="line">            </div><div class="line">            <span class="comment">// right</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = i + <span class="number">1</span>; k &lt; n - i; k++) &#123;</div><div class="line">                matrix[k][n - <span class="number">1</span> - j] = ++count;</div><div class="line">            &#125;</div><div class="line">            </div><div class="line">            <span class="comment">// bottom</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = n - <span class="number">2</span> - j; k &gt;= j; k--) &#123;</div><div class="line">                matrix[n - <span class="number">1</span> - i][k] = ++count;</div><div class="line">            &#125;</div><div class="line">            </div><div class="line">            <span class="comment">// left</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = n - <span class="number">2</span> - i; k &gt; i; k--) &#123;</div><div class="line">                matrix[k][j] = ++count;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> matrix;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/spiral-matrix-ii/description/" target="_blank" rel="external">https://leetcode.com/problems/spiral-matrix-ii/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode 59. Spiral Matrix II
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Linux GDB调试C++程序</title>
    <link href="http://noahsnail.com/2018/07/11/2018-07-11-Linux%20GDB%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F/"/>
    <id>http://noahsnail.com/2018/07/11/2018-07-11-Linux GDB调试程序/</id>
    <published>2018-07-11T08:10:25.000Z</published>
    <updated>2018-07-11T08:10:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-编译C-程序"><a href="#1-编译C-程序" class="headerlink" title="1. 编译C++程序"></a>1. 编译C++程序</h2><p>要编译的C++程序如下，文件名为<code>spiral_matrix.cpp</code>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; spiralOrder(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt;&amp; matrix) &#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result;</div><div class="line">        <span class="keyword">int</span> rows = matrix.size();</div><div class="line">        <span class="keyword">if</span>(rows == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> result;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> columns = matrix[<span class="number">0</span>].size();</div><div class="line">        <span class="keyword">int</span> total = rows * columns;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; result.size() &lt; total; i++, j++) &#123;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// top</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = j; k &lt; columns - j; k++) &#123;</div><div class="line">                    result.push_back(matrix[i][k]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// right</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = i + <span class="number">1</span>; k &lt; rows - i; k++) &#123;</div><div class="line">                    result.push_back(matrix[k][columns - <span class="number">1</span> - j]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// bottom</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = columns - <span class="number">2</span> - j; k &gt;= j; k--) &#123;</div><div class="line">                    result.push_back(matrix[rows - <span class="number">1</span> - i][k]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// left</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = rows - <span class="number">2</span> - i; k &gt; i; k--) &#123;</div><div class="line">                    result.push_back(matrix[k][j]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">    Solution s;</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</div><div class="line">    temp.push_back(<span class="number">6</span>);</div><div class="line">    temp.push_back(<span class="number">9</span>);</div><div class="line">    temp.push_back(<span class="number">7</span>);</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; matrix;</div><div class="line">    matrix.push_back(temp);</div><div class="line">    s.spiralOrder(matrix);</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>使用<code>g++</code>进行编译，编译命令为<code>g++ -g spiral_matrix.cpp -o test</code>，<code>-g</code>参数表示编译时加入调试信息。</p>
<h2 id="2-GDB调试"><a href="#2-GDB调试" class="headerlink" title="2. GDB调试"></a>2. GDB调试</h2><p>执行命令<code>gdb test</code>进入调试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7</div><div class="line">Copyright (C) 2013 Free Software Foundation, Inc.</div><div class="line">License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;</div><div class="line">This is free software: you are free to change and redistribute it.</div><div class="line">There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;</div><div class="line">and &quot;show warranty&quot; for details.</div><div class="line">This GDB was configured as &quot;x86_64-redhat-linux-gnu&quot;.</div><div class="line">For bug reporting instructions, please see:</div><div class="line">&lt;http://www.gnu.org/software/gdb/bugs/&gt;...</div><div class="line">Reading symbols from /home1/irteam/line-brain/tianchi/acm/test...done.</div><div class="line">(gdb)</div></pre></td></tr></table></figure>
<p>输入命令<code>list 10</code>查看代码，<code>list &lt;line_number&gt;</code>表示查看某行代码附近的代码。<code>list 10</code>也可简写为<code>l 10</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">(gdb) list 10</div><div class="line">5       class Solution &#123;</div><div class="line">6       public:</div><div class="line">7           vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt; &gt;&amp; matrix) &#123;</div><div class="line">8               vector&lt;int&gt; result;</div><div class="line">9               int rows = matrix.size();</div><div class="line">10              if(rows == 0) &#123;</div><div class="line">11                  return result;</div><div class="line">12              &#125;</div><div class="line">13              int columns = matrix[0].size();</div><div class="line">14              int total = rows * columns;</div><div class="line">(gdb) l 10</div><div class="line">5       class Solution &#123;</div><div class="line">6       public:</div><div class="line">7           vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt; &gt;&amp; matrix) &#123;</div><div class="line">8               vector&lt;int&gt; result;</div><div class="line">9               int rows = matrix.size();</div><div class="line">10              if(rows == 0) &#123;</div><div class="line">11                  return result;</div><div class="line">12              &#125;</div><div class="line">13              int columns = matrix[0].size();</div><div class="line">14              int total = rows * columns;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Linux GDB调试程序
    
    </summary>
    
      <category term="Linux" scheme="http://noahsnail.com/categories/Linux/"/>
    
    
      <category term="C++" scheme="http://noahsnail.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode54——Spiral Matrix</title>
    <link href="http://noahsnail.com/2018/07/11/2018-07-11-Leetcode54%E2%80%94%E2%80%94Spiral%20Matrix/"/>
    <id>http://noahsnail.com/2018/07/11/2018-07-11-Leetcode54——Spiral Matrix/</id>
    <published>2018-07-11T07:17:17.000Z</published>
    <updated>2018-07-11T07:27:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-7b7f0fe07774f6c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Spiral Matrix"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; spiralOrder(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix) &#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result;</div><div class="line">        <span class="keyword">int</span> rows = matrix.size();</div><div class="line">        <span class="keyword">if</span>(rows == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> result;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> columns = matrix[<span class="number">0</span>].size();</div><div class="line">        <span class="keyword">int</span> total = rows * columns;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; result.size() &lt; total; i++, j++) &#123;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// top</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = j; k &lt; columns - j; k++) &#123;</div><div class="line">                    result.push_back(matrix[i][k]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// right</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = i + <span class="number">1</span>; k &lt; rows - i; k++) &#123;</div><div class="line">                    result.push_back(matrix[k][columns - <span class="number">1</span> - j]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// bottom</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = columns - <span class="number">2</span> - j; k &gt;= j; k--) &#123;</div><div class="line">                    result.push_back(matrix[rows - <span class="number">1</span> - i][k]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span>(result.size() &lt; total) &#123;</div><div class="line">                <span class="comment">// left</span></div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = rows - <span class="number">2</span> - i; k &gt; i; k--) &#123;</div><div class="line">                    result.push_back(matrix[k][j]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/spiral-matrix/description/" target="_blank" rel="external">https://leetcode.com/problems/spiral-matrix/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode54——Spiral Matrix
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode55——Jump Game</title>
    <link href="http://noahsnail.com/2018/07/10/2018-07-10-Leetcode55%E2%80%94%E2%80%94Jump%20Game/"/>
    <id>http://noahsnail.com/2018/07/10/2018-07-10-Leetcode55——Jump Game/</id>
    <published>2018-07-10T10:22:01.000Z</published>
    <updated>2018-07-13T06:15:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-d77ed2dd11c517c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Jump Game"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><ul>
<li>递归遍历所有的可能</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canJump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> jump(nums, <span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">jump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> start)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span>(start + nums[start] &gt;= nums.size() - <span class="number">1</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= nums[start]; i++) &#123;</div><div class="line">            <span class="keyword">if</span>(nums[start + i] != <span class="number">0</span>) &#123;</div><div class="line">                <span class="keyword">if</span>(jump(nums, start + i)) &#123;</div><div class="line">                    <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> &#123;</div><div class="line">                    nums[start + i] = <span class="number">0</span>;   </div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        nums[start] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>贪心算法</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">canJump</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> current = nums.size() - <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = current - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">            <span class="keyword">if</span>(nums[i] + i &gt;= current) &#123;</div><div class="line">                current = i;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span>(current == <span class="number">0</span>) &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/jump-game/description/" target="_blank" rel="external">https://leetcode.com/problems/jump-game/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode55——Jump Game
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode18——4Sum</title>
    <link href="http://noahsnail.com/2018/07/09/2018-07-09-Leetcode18%E2%80%94%E2%80%944Sum/"/>
    <id>http://noahsnail.com/2018/07/09/2018-07-09-Leetcode18——4Sum/</id>
    <published>2018-07-09T05:33:14.000Z</published>
    <updated>2018-07-09T09:29:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-6056743319267817.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4Sum"></p>
<h2 id="2-Solutions"><a href="#2-Solutions" class="headerlink" title="2. Solutions"></a>2. Solutions</h2><ul>
<li><p>Brute Force</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; fourSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</div><div class="line">        <span class="keyword">int</span> length = nums.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; result;</div><div class="line">        sort(nums.begin(), nums.end());</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length - <span class="number">3</span>; i++) &#123;</div><div class="line">            <span class="keyword">if</span>(i != <span class="number">0</span> &amp;&amp; nums[i] == nums[i - <span class="number">1</span>]) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; length - <span class="number">2</span>; j++) &#123;</div><div class="line">                <span class="keyword">if</span>(nums[j] == nums[j - <span class="number">1</span>] &amp;&amp; j != i + <span class="number">1</span>) &#123;</div><div class="line">                    <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = j + <span class="number">1</span>; k &lt; length - <span class="number">1</span>; k++) &#123;</div><div class="line">                    <span class="keyword">if</span>(nums[k] == nums[k - <span class="number">1</span>] &amp;&amp; k != j + <span class="number">1</span>) &#123;</div><div class="line">                        <span class="keyword">continue</span>;</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> l = k + <span class="number">1</span>; l &lt; length; l++) &#123;</div><div class="line">                        <span class="keyword">if</span>(nums[l] == nums[l - <span class="number">1</span>] &amp;&amp; l != k + <span class="number">1</span>) &#123;</div><div class="line">                            <span class="keyword">continue</span>;</div><div class="line">                        &#125;</div><div class="line">                        <span class="keyword">int</span> sum = nums[i] + nums[j] + nums[k] + nums[l];</div><div class="line">                        <span class="keyword">if</span>(sum == target) &#123;</div><div class="line">                            <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</div><div class="line">                            temp.push_back(nums[i]);</div><div class="line">                            temp.push_back(nums[j]);</div><div class="line">                            temp.push_back(nums[k]);</div><div class="line">                            temp.push_back(nums[l]);</div><div class="line">                            result.push_back(temp);</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
<li><p>sort and O(n^3)</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; fourSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</div><div class="line">        <span class="keyword">int</span> length = nums.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; result;</div><div class="line">        sort(nums.begin(), nums.end());</div><div class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> newTarget = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length - <span class="number">3</span>; i++) &#123;</div><div class="line">            <span class="keyword">if</span>(i != <span class="number">0</span> &amp;&amp; nums[i] == nums[i - <span class="number">1</span>]) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; length - <span class="number">2</span>; j++) &#123;</div><div class="line">                <span class="keyword">if</span>(nums[j] == nums[j - <span class="number">1</span>] &amp;&amp; j != i + <span class="number">1</span>) &#123;</div><div class="line">                    <span class="keyword">continue</span>;</div><div class="line">                &#125;</div><div class="line">                newTarget = target - nums[i] - nums[j];</div><div class="line">                left = j + <span class="number">1</span>;</div><div class="line">                right = length - <span class="number">1</span>;</div><div class="line">                <span class="keyword">while</span>(left &lt; right) &#123;</div><div class="line">                    <span class="keyword">if</span>(left != j + <span class="number">1</span> &amp;&amp; nums[left] == nums[left - <span class="number">1</span>]) &#123;</div><div class="line">                        left++;</div><div class="line">                        <span class="keyword">continue</span>;</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">if</span>(right &lt; length - <span class="number">2</span> &amp;&amp; nums[right] == nums[right + <span class="number">1</span>]) &#123;</div><div class="line">                        right--;</div><div class="line">                        <span class="keyword">continue</span>;</div><div class="line">                    &#125;</div><div class="line">                    sum = nums[left] + nums[right];</div><div class="line">                    <span class="keyword">if</span>(sum == newTarget) &#123;</div><div class="line">                        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</div><div class="line">                        temp.push_back(nums[i]);</div><div class="line">                        temp.push_back(nums[j]);</div><div class="line">                        temp.push_back(nums[left]);</div><div class="line">                        temp.push_back(nums[right]);</div><div class="line">                        result.push_back(temp);</div><div class="line">                        left++;</div><div class="line">                        right--;</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(sum &lt; newTarget) &#123;</div><div class="line">                        left++;</div><div class="line">                    &#125;</div><div class="line">                    <span class="keyword">else</span> &#123;</div><div class="line">                        right--;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">                </div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/4sum/description/" target="_blank" rel="external">https://leetcode.com/problems/4sum/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode18——4Sum
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode16——3Sum Closest</title>
    <link href="http://noahsnail.com/2018/07/06/2018-07-06-Leetcode16%E2%80%94%E2%80%943Sum%20Closest/"/>
    <id>http://noahsnail.com/2018/07/06/2018-07-06-Leetcode16——3Sum Closest/</id>
    <published>2018-07-06T06:27:53.000Z</published>
    <updated>2018-07-06T06:28:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-0b8638d18c7026f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="3Sum Closest"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><ul>
<li>Brute Force</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">threeSumClosest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> length = nums.size();</div><div class="line">        <span class="keyword">int</span> sum = nums[<span class="number">0</span>] + nums[<span class="number">1</span>] + nums[<span class="number">2</span>];</div><div class="line">        <span class="keyword">int</span> min = <span class="built_in">abs</span>(sum - target);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; length; j++) &#123;</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = j + <span class="number">1</span>; k &lt; length; k++) &#123;</div><div class="line">                    <span class="keyword">int</span> temp = nums[i] + nums[j] + nums[k];</div><div class="line">                    <span class="keyword">int</span> diff = <span class="built_in">abs</span>(temp - target);</div><div class="line">                    <span class="keyword">if</span>(min &gt; diff) &#123;</div><div class="line">                        min = diff;</div><div class="line">                        sum = temp;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> sum;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>sort and O(n^2)</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">threeSumClosest</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</div><div class="line">        <span class="comment">// sort vector</span></div><div class="line">        sort(nums.begin(), nums.end());</div><div class="line">        <span class="keyword">int</span> length = nums.size();</div><div class="line">        <span class="keyword">int</span> sum = nums[<span class="number">0</span>] + nums[<span class="number">1</span>] + nums[<span class="number">2</span>];</div><div class="line">        <span class="keyword">int</span> min = <span class="built_in">abs</span>(sum - target);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length - <span class="number">2</span>; i++) &#123;</div><div class="line">            <span class="keyword">int</span> left = i + <span class="number">1</span>;</div><div class="line">            <span class="keyword">int</span> right = length - <span class="number">1</span>;</div><div class="line">            <span class="keyword">while</span>(left &lt; right) &#123;</div><div class="line">                <span class="keyword">int</span> temp = nums[i] + nums[left] + nums[right];</div><div class="line">                <span class="keyword">int</span> diff = <span class="built_in">abs</span>(temp - target);</div><div class="line">                <span class="keyword">if</span>(min &gt; diff) &#123;</div><div class="line">                    min = diff;</div><div class="line">                    sum = temp;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span>(temp &lt; target) &#123;</div><div class="line">                    left++;</div><div class="line">                &#125; </div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(temp &gt; target) &#123;</div><div class="line">                    right--;</div><div class="line">                &#125; </div><div class="line">                <span class="keyword">else</span> &#123;</div><div class="line">                    <span class="keyword">return</span> temp;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> sum;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://leetcode.com/problems/3sum-closest/description/" target="_blank" rel="external">https://leetcode.com/problems/3sum-closest/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode16——3Sum Closest
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Caffe训练时Loss不下降问题</title>
    <link href="http://noahsnail.com/2018/07/05/2018-07-05-Caffe%E8%AE%AD%E7%BB%83%E6%97%B6Loss%E4%B8%8D%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/"/>
    <id>http://noahsnail.com/2018/07/05/2018-07-05-Caffe训练时Loss不下降问题/</id>
    <published>2018-07-05T05:53:40.000Z</published>
    <updated>2018-07-05T08:21:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p>今天使用Caffe进行分类模型训练时，迭代到一定次数后loss突然增大到某个固定值，然后保持不变。日志如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">I0705 14:57:14.980687   320 solver.cpp:218] Iteration 44 (2.60643 iter/s, 0.383667s/1 iters), loss = 0.263664</div><div class="line">I0705 14:57:14.980741   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 0.878881 (* 0.3 = 0.263664 loss)</div><div class="line">I0705 14:57:14.980756   320 sgd_solver.cpp:105] Iteration 44, lr = 0.000956</div><div class="line">I0705 14:57:15.365164   320 solver.cpp:218] Iteration 45 (2.60146 iter/s, 0.3844s/1 iters), loss = 20.7475</div><div class="line">I0705 14:57:15.365226   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 69.1584 (* 0.3 = 20.7475 loss)</div><div class="line">I0705 14:57:15.365243   320 sgd_solver.cpp:105] Iteration 45, lr = 0.000955</div><div class="line">I0705 14:57:15.759548   320 solver.cpp:218] Iteration 46 (2.53612 iter/s, 0.394303s/1 iters), loss = 0</div><div class="line">I0705 14:57:15.759609   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 0 (* 0.3 = 0 loss)</div><div class="line">I0705 14:57:15.759624   320 sgd_solver.cpp:105] Iteration 46, lr = 0.000954</div><div class="line">I0705 14:57:16.158644   320 solver.cpp:218] Iteration 47 (2.50621 iter/s, 0.39901s/1 iters), loss = 1.63756</div><div class="line">I0705 14:57:16.158696   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 5.45853 (* 0.3 = 1.63756 loss)</div><div class="line">I0705 14:57:16.158715   320 sgd_solver.cpp:105] Iteration 47, lr = 0.000953</div><div class="line">I0705 14:57:16.546782   320 solver.cpp:218] Iteration 48 (2.57693 iter/s, 0.388058s/1 iters), loss = 3.27512</div><div class="line">I0705 14:57:16.546838   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 10.9171 (* 0.3 = 3.27512 loss)</div><div class="line">I0705 14:57:16.546855   320 sgd_solver.cpp:105] Iteration 48, lr = 0.000952</div><div class="line">I0705 14:57:16.930493   320 solver.cpp:218] Iteration 49 (2.60667 iter/s, 0.383631s/1 iters), loss = 25.3822</div><div class="line">I0705 14:57:16.930553   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 84.6073 (* 0.3 = 25.3822 loss)</div><div class="line">I0705 14:57:16.930568   320 sgd_solver.cpp:105] Iteration 49, lr = 0.000951</div><div class="line">I0705 14:57:17.314102   320 solver.cpp:218] Iteration 50 (2.60741 iter/s, 0.383522s/1 iters), loss = 26.201</div><div class="line">I0705 14:57:17.314185   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 87.3365 (* 0.3 = 26.201 loss)</div><div class="line">I0705 14:57:17.314213   320 sgd_solver.cpp:105] Iteration 50, lr = 0.00095</div><div class="line">I0705 14:57:17.695567   320 solver.cpp:218] Iteration 51 (2.62216 iter/s, 0.381364s/1 iters), loss = 26.201</div><div class="line">I0705 14:57:17.695627   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 87.3365 (* 0.3 = 26.201 loss)</div><div class="line">I0705 14:57:17.695642   320 sgd_solver.cpp:105] Iteration 51, lr = 0.000949</div><div class="line">I0705 14:57:18.077605   320 solver.cpp:218] Iteration 52 (2.61813 iter/s, 0.381953s/1 iters), loss = 26.201</div><div class="line">I0705 14:57:18.077667   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 87.3365 (* 0.3 = 26.201 loss)</div><div class="line">I0705 14:57:18.077684   320 sgd_solver.cpp:105] Iteration 52, lr = 0.000948</div><div class="line">I0705 14:57:18.461403   320 solver.cpp:218] Iteration 53 (2.60613 iter/s, 0.383711s/1 iters), loss = 26.201</div><div class="line">I0705 14:57:18.461458   320 solver.cpp:237]     Train net output #0: loss1/loss1 = 87.3365 (* 0.3 = 26.201 loss)</div></pre></td></tr></table></figure>
<h2 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2. 解决方案"></a>2. 解决方案</h2><p>调整参数，例如学习率之类的都没用。调查发现finetune时冻结了BN层的参数(即<code>batch_norm_param</code>中的<code>use_global_stats</code>设置为<code>true</code>)，将其<code>use_global_stats</code>设置为<code>false</code>，问题解决。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://blog.csdn.net/u010911921/article/details/71079367" target="_blank" rel="external">https://blog.csdn.net/u010911921/article/details/71079367</a></li>
<li><a href="https://github.com/BVLC/caffe/issues/3347" target="_blank" rel="external">https://github.com/BVLC/caffe/issues/3347</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Caffe训练时Loss不下降问题
    
    </summary>
    
      <category term="Caffe" scheme="http://noahsnail.com/categories/Caffe/"/>
    
    
      <category term="Caffe" scheme="http://noahsnail.com/tags/Caffe/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode11——Container With Most Water</title>
    <link href="http://noahsnail.com/2018/07/05/2018-07-05-Leetcode11%E2%80%94%E2%80%94Container%20With%20Most%20Water/"/>
    <id>http://noahsnail.com/2018/07/05/2018-07-05-Leetcode11——Container With Most Water/</id>
    <published>2018-07-05T02:14:15.000Z</published>
    <updated>2018-07-05T05:52:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-Description"><a href="#1-Description" class="headerlink" title="1. Description"></a>1. Description</h2><p><img src="https://upload-images.jianshu.io/upload_images/3232548-c5b008b2df8dcddf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Container With Most Water"></p>
<h2 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h2><ul>
<li>Brute Force</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxArea</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> length = height.size();</div><div class="line">        <span class="keyword">int</span> maxArea = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> area = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; length; j++) &#123;</div><div class="line">                area = (j - i) * (height[i]&lt;height[j]?height[i]:height[j]);</div><div class="line">                <span class="keyword">if</span>(maxArea &lt; area) &#123;</div><div class="line">                    maxArea = area;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> maxArea;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>Two Pointer Approach<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxArea</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; height)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> j = height.size() - <span class="number">1</span>;</div><div class="line">        <span class="keyword">int</span> maxArea = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> area = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span>(i &lt; j) &#123;</div><div class="line">            area = (j - i) * (height[i]&lt;height[j]?height[i]:height[j]);</div><div class="line">            <span class="keyword">if</span>(maxArea &lt; area) &#123;</div><div class="line">                maxArea = area;</div><div class="line">            &#125;</div><div class="line">            height[i]&lt;height[j]?i++:j--;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> maxArea;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://leetcode.com/problems/container-with-most-water/description/" target="_blank" rel="external">https://leetcode.com/problems/container-with-most-water/description/</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Leetcode11——Container With Most Water
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode35——Search Insert Position</title>
    <link href="http://noahsnail.com/2018/07/05/2018-07-05-Leetcode35%E2%80%94%E2%80%94Search%20Insert%20Position/"/>
    <id>http://noahsnail.com/2018/07/05/2018-07-05-Leetcode35——Search Insert Position/</id>
    <published>2018-07-05T01:37:03.000Z</published>
    <updated>2018-07-05T01:37:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p>Given a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.</p>
<p>You may assume no duplicates in the array.</p>
<p><strong>Example 1</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: [1,3,5,6], 5</div><div class="line">Output: 2</div></pre></td></tr></table></figure></p>
<p><strong>Example 2</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: [1,3,5,6], 2</div><div class="line">Output: 1</div></pre></td></tr></table></figure></p>
<p><strong>Example 3</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: [1,3,5,6], 7</div><div class="line">Output: 4</div></pre></td></tr></table></figure></p>
<p><strong>Example 4</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: [1,3,5,6], 0</div><div class="line">Output: 0</div></pre></td></tr></table></figure></p>
<h2 id="2-求解"><a href="#2-求解" class="headerlink" title="2. 求解"></a>2. 求解</h2><p><strong>Solution(C++)</strong>:</p>
<p>这道题就是一个二分查找问题。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">searchInsert</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> right = nums.size() - <span class="number">1</span>;</div><div class="line">        <span class="keyword">int</span> middle = <span class="number">0</span>;</div><div class="line">        <span class="keyword">while</span>(left &lt;= right) &#123;</div><div class="line">            middle = (left + right) / <span class="number">2</span>;</div><div class="line">            <span class="keyword">if</span>(nums[middle] &lt; target) &#123;</div><div class="line">                left = middle + <span class="number">1</span>;</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[middle] &gt; target) &#123;</div><div class="line">                right = middle - <span class="number">1</span>;</div><div class="line">            &#125; </div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                <span class="keyword">return</span> middle;  </div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> left;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Leetcode35——Search Insert Position
    
    </summary>
    
      <category term="基础算法" scheme="http://noahsnail.com/categories/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="http://noahsnail.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Caffe与NVIDIA Docker不兼容的问题</title>
    <link href="http://noahsnail.com/2018/06/27/2018-06-27-Caffe%E4%B8%8ENVIDIA%20Docker%E4%B8%8D%E5%85%BC%E5%AE%B9%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://noahsnail.com/2018/06/27/2018-06-27-Caffe与NVIDIA Docker不兼容的问题/</id>
    <published>2018-06-27T09:21:02.000Z</published>
    <updated>2018-11-26T10:12:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p>今天在使用Dockerfile构建Caffe Docker Image时碰到了一个Caffe与NVIDIA Docker不兼容的问题，我使用的NVIDIA Docker为<code>FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04</code>，出现的错误为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nvcc fatal   : Unsupported gpu architecture &apos;compute_20&apos;</div></pre></td></tr></table></figure>
<p>解决方案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 在Dockerfile中添加</div><div class="line">ENV CUDA_ARCH_BIN &quot;35 52 60 61 70&quot;</div><div class="line">ENV CUDA_ARCH_PTX &quot;52 70&quot;</div><div class="line"></div><div class="line"># 在CMake时添加参数</div><div class="line"></div><div class="line">-DCUDA_ARCH_NAME=Manual -DCUDA_ARCH_BIN=$&#123;CUDA_ARCH_BIN&#125; -DCUDA_ARCH_PTX=$&#123;CUDA_ARCH_PTX&#125;</div></pre></td></tr></table></figure>
<p>注意：<code>35 52 60 61 70</code>是CUDA显卡的计算能力。<code>CUDA_ARCH_BIN</code>参数指定的是显卡的计算能力，<code>CUDA_ARCH_PTX</code>是PTX代码生成的对应库文件，与显卡计算能力对应。<code>CUDA_ARCH_PTX</code>必须包含你的显卡，否则会报错。错误如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Check failed: error == cudaSuccess (48 vs. 0) no kernel image is available for execution on the device</div></pre></td></tr></table></figure></p>
<p>显卡计算能力查询可参考资料2。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://github.com/NVIDIA/nvidia-docker/issues/597" target="_blank" rel="external">https://github.com/NVIDIA/nvidia-docker/issues/597</a></li>
<li><a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="external">https://developer.nvidia.com/cuda-gpus</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      Caffe与NVIDIA Docker不兼容的问题
    
    </summary>
    
      <category term="Caffe" scheme="http://noahsnail.com/categories/Caffe/"/>
    
    
      <category term="Caffe" scheme="http://noahsnail.com/tags/Caffe/"/>
    
  </entry>
  
  <entry>
    <title>An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中英文对照</title>
    <link href="http://noahsnail.com/2018/06/15/2018-06-15-An%20end-to-end%20TextSpotter%20with%20Explicit%20Alignment%20and%20Attention%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AF%B9%E7%85%A7/"/>
    <id>http://noahsnail.com/2018/06/15/2018-06-15-An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中英文对照/</id>
    <published>2018-06-15T01:52:19.000Z</published>
    <updated>2018-06-18T07:20:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p><strong>声明：作者翻译论文仅为学习，如有侵权请联系作者删除博文，谢谢！</strong></p>
<p>翻译论文汇总：<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank" rel="external">https://github.com/SnailTyan/deep-learning-papers-translation</a></p>
<h1 id="An-end-to-end-TextSpotter-with-Explicit-Alignment-and-Attention"><a href="#An-end-to-end-TextSpotter-with-Explicit-Alignment-and-Attention" class="headerlink" title="An end-to-end TextSpotter with Explicit Alignment and Attention"></a>An end-to-end TextSpotter with Explicit Alignment and Attention</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Text detection and recognition in natural images have long been considered as two separate tasks that are processed sequentially. Training of two tasks in a unified framework is non-trivial due to significant differences in optimisation difficulties. In this work, we present a conceptually simple yet efficient framework that simultaneously processes the two tasks in one shot. Our main contributions are three-fold: 1) we propose a novel text-alignment layer that allows it to precisely compute convolutional features of a text instance in arbitrary orientation, which is the key to boost the performance; 2) a character attention mechanism is introduced by using character spatial information as explicit supervision, leading to large improvements in recognition; 3) two technologies, together with a new RNN branch for word recognition, are integrated seamlessly into a single model which is end-to-end trainable. This allows the two tasks to work collaboratively by sharing convolutional features, which is critical to identify challenging text instances. Our model achieves impressive results in end-to-end recognition on the ICDAR2015 [1] dataset, significantly advancing most recent results [2], with improvements of F-measure from (0.54, 0.51, 0.47) to (0.82, 0.77, 0.63), by using a strong, weak and generic lexicon respectively. Thanks to joint training, our method can also serve as a good detector by achieving a new state-of-the-art detection performance on two datasets.</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>长期以来，自然图像中的文本检测和识别被视为按顺序处理的两个独立任务。由于优化难度存在显着差异，在统一框架下培训两项任务并不重要。在这项工作中，我们提出了一个概念简单而高效的框架，可以同时处理两个任务。我们的主要贡献有三个：1）我们提出了一种新颖的文本对齐层，允许它精确地计算任意方向的文本实例的卷积特征，这是提高性能的关键；2）将字符空间信息作为显式监督引入角色注意机制，导致识别率大幅提高; 3）两种技术，连同一个新的RNN分支用于单词识别，可以无缝集成到一个端到端可训练的单一模型中。这允许两个任务通过共享卷积特征来协作工作，这对识别具有挑战性的文本实例是至关重要的。我们的模型在ICDAR2015 [1]数据集端到端识别方面取得了令人印象深刻的结果，显着推进了最新的研究成果[2]，F-度量从（0.54,0.51,0.47）提高到（0.82,0.77,0.63 ），分别使用强，弱和通用的词典。得益于联合训练，我们的方法还可以作为一个很好的检测器，通过在两个数据集上实现新的最先进的检测性能。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The goal of text spotting is to map an input natural image into a set of character sequences or word transcripts and corresponding location. It has attracted increasing attention in the vision community, due to its numerous potential applications. It has made rapid progress riding on the wave of recent deep learning technologies, as substantiated by recent works [3, 4, 2, 5, 6, 7, 8, 9, 10, 11]. However, text spotting in the wild still remains an open problem, since text instances often exhibit vast diversity in font, scale and orientation with various illumination affects, which often come with a highly complicated background.</p>
<p>Past works in text spotting often consider it as two individual tasks: text detection and word recognition, which are implemented sequentially. The goal of text detection is to precisely localize all text instances (e.g., words) in a natural image, and then a recognition model is processed repeatedly through all detected regions for recognizing corresponding text transcripts. Recent approaches for text detection are mainly extended from general object detectors (such as Faster R-CNN [12] and SSD [13]) by directly regressing a bounding box for each text instance, or from semantic segmentation methods (e.g., Fully Convolutional Networks (FCN) [14]) by predicting a text/non-text probability at each pixel. With careful model design and development, these approaches can be customized properly towards this highly domain-specific task, and achieve the state-of-the-art performance [4, 6, 7, 8, 9, 15]. The word recognition can be cast into a sequence labeling problem where convolutional recurrent models have been developed recently [9, 16]. Some of them were further incorporated with an attention mechanism for improving the performance [17, 18]. However, training two tasks separately does not exploit the full potential of convolutional networks, where the convolutional features are not shared. It is natural for us to make a more reliable decision if we clearly understand or recognize the meaning of a word and all characters within it. Besides, it is also possible to introduce a number of heuristic rules and hyper-parameters that are costly to tune, making the whole system highly complicated.</p>
<p>Recent Mask R-CNN [19] incorporates an instance segmentation task into the Faster R-CNN [12] detection framework, resulting in a multi-task learning model that jointly predicts a bounding box and a segmentation mask for each object instance. Our work draws inspiration from this pipeline, but has a different goal of learning a direct mapping between an input image and a set of character sequences. We create a recurrent sequence modeling branch for word recognition within a text detection framework, where the RNN based word recognition is processed in parallel to the detection task.</p>
<p>However, the RNN branch, where the gradients are back-propagated through time, is clearly much more difficult to optimize than the task of bounding box regression in detection. This naturally leads to significant differences in learning difficulties and convergence rates between two tasks, making the model particularly hard to be trained jointly. For example, the magnitude of images for training a text detection model is about 103 (e.g., 1000 training images in the ICDAR 2015 [1]) , but the number is increased significantly by many orders of magnitude when a RNN based text recognition model is trained, such as the 800K synthetic images used in [20]. Furthermore, simply using a set of character sequences as direct supervision may be too abstractive (high-level) to provide meaningful detailed information for training such an integrated model effectively, which will make the model difficult to convergence. In this work, we introduce strong spatial constraints in both word and character levels, which allows the model to be optimized gradually by reducing the search space at each step.</p>
<p>Contributions In this work, we present a single-shot textspotter capable of learning a direct mapping between an input image and a set of character sequences or word transcripts. We propose a solution that combines a text-alignment layer tailed for multi-orientation text detection, together with a character attention mechanism that explicitly encodes strong spatial information of characters into the RNN branch, as shown in Fig. 1. These two technologies faithfully preserve the exact spatial information in both text instance and character levels, playing a key role in boosting the overall performance. We develop a principled learning strategy that allows the two tasks to be trained collaboratively by sharing convolutional features. Our main contributions are described as follows.</p>
<p>Firstly, we develop a text-alignment layer by introducing a grid sampling scheme instead of conventional RoI pooling. It computes fixed-length convolutional features that precisely align to a detected text region of arbitrary orientation, successfully avoiding the negative effects caused by orientation changing and quantization factor of the RoI pooling.</p>
<p>Secondly, we introduce a character attention mechanism by using character spatial information as an addition supervision. This explicitly encodes strong spatial attentions of characters into the model, which allows the RNN to focus on current attentional features in decoding, leading to performance boost in word recognition.</p>
<p>Thirdly, both approaches, together with a new RNN branch for word recognition, are integrated elegantly into a CNN detection framework, resulting in a single model that can be trained in an end-to-end manner. We develop a principled and intuitive learning strategy that allows the two tasks to be trained effectively by sharing features, with fast convergence.</p>
<p>Finally, we show by experiments that word recognition can significantly improve detection accuracy in our model, demonstrating strong complementary nature of them, which is unique to this highly domain-specific application. Our model achieves new state-of-the-art results on the ICDAR2015 in end-to-end recognition of multi-orientation texts, largely outperforming the most recent results in [2], with improvements of F-measure from (0.54, 0.51, 0.47) to (0.82, 0.77, 0.63) in terms of using a strong, weak and generic lexicon. Code is avail- able at <a href="https://github.com/tonghe90/textspotter" target="_blank" rel="external">https://github.com/tonghe90/textspotter</a></p>
<p><strong>Related work</strong> Here we briefly introduce some related works on text detection, recognition and end-to-end wordspotting.</p>
<p><em>Scene text detection</em> Recently, some methods cast previous character based detection [21, 22, 23, 24] into direct text region estimation [25, 8, 15, 26, 4, 27, 28], avoiding multiple bottom-up post-processing steps by taking word or text-line as a whole. Tian et al. [7] modified Faster-RCNN [12] by applying a recurrent structure on the convolution feature maps of the top layer horizontally. The methods in [4, 25] were inspired from [13]. They both explored the framework from generic objects and convert to scene text detection by adjusting the feature extraction process to this domain-specific task. However, these methods are based on prior boxes, which need to be carefully designed in order to fulfill the requirements for training. Methods of direct regression for inclined bounding boxes, instead of offsets to fixed prior boxes, have been proposed recently. EAST [8] designed a fully convolutional network structure which outputs a pixel-wise prediction map for text/non-text and five values for every point of text region, i.e., distances from the current point to the four edges with an inclined angle. He et al. [6] proposed a method to generate arbitrary quadrilaterals by calculating offsets between every point of text region and vertex coordinates.</p>
<p>Scene text recognition With the success of recurrent neural networks on digit recognition and speech translation, a lot of works have been proposed for text recognition. He et al. [16] and Shi et al. [9, 29] treat text recognition as a sequence labeling problem by introducing LSTM [30] and connectionist temporal classification (CTC) [31] into a unified framework. [17] proposed an attention-based LSTM for text recognition, which mainly contains two parts: encoder and decoder. In the encoding stage, text images are transformed into a sequence of feature vectors by CNN/LSTM. Attention weights, indicating relative importance for recognition, will be learned during the decoding stage. However, these weights are totally learned by the distribution of data and no supervision is provided to guide the learning process.</p>
<p><em>End-to-end wordspotting</em> End-to-end wordspotting is an emerging research area. Previous methods usually try to solve it by splitting the whole process into two independent problems: training two cascade models, one for detection and one for recognition. Detected text regions are firstly cropped from original image, followed by affine transforming and rescaling. Corrected images are repeatedly precessed by recognition model to get corresponding transcripts. However, training errors will be accumulated due to cascading models without sharable features. Li et al. [5] proposed a unified network that simultaneously localizes and recognizes text in one forward pass by sharing convolution features under a curriculum strategy. But the existing RoI pooling operation limits it to detect and recognize only horizontal examples. Busta et al. [2] brought up deep text spotter, which can solve wordspotting of multi-orientation problem. However, the method does not have sharable feature, meaning that the recognition loss of the later stage has no influence on the former localization results.</p>
<h2 id="2-Single-Shot-TextSpotter-by-Joint-Detection-and-Recognition"><a href="#2-Single-Shot-TextSpotter-by-Joint-Detection-and-Recognition" class="headerlink" title="2. Single Shot TextSpotter by Joint Detection and Recognition"></a>2. Single Shot TextSpotter by Joint Detection and Recognition</h2><p>In this section, we present the details of the proposed textspotter which learns a direct mapping between an input image and a set of word transcripts with corresponding bounding boxes of arbitrary orientations. Our model is a fully convolutional architecture built on the PVAnet framework [32]. As shown in Fig. 2, we introduce a new recurrent branch for word recognition, which is integrated into our CNN model in parallel with the existing detection branch for text bounding box regression. The RNN branch is composed of a new text-alignment layer and a LSTM-based recurrent module with a novel character attention embedding mechanism. The text-alignment layer extracts precise sequence feature within the detected region, preventing encoding irrelevant texts or background information. The character attention embedding mechanism regulates the decoding process by providing more detailed supervisions of characters. Our textspotter directly outputs final results in one shot, without any post-processing step except for a simple non-maximum suppression (NMS).</p>
<p>Network architecture Our model is a fully convolutional architecture inspired by [8], where a PVA network [32] is utilized as backbone due to its significantly low computational cost. Unlike generic objects, texts often have a much larger variations in both sizes and aspect ratios. Thus it not only needs to preserve local details for small-scale text instances, but also should maintain a large receptive field for very long instances. Inspired by the success in semantic segmentation [33], we exploit feature fusion by combining convolutional features of conv5, conv4, conv3 and conv2 layers gradually, with the goal of maintaining both local detailed features and high-level context information. This results in more reliable predictions on multi-scale text instances. Size of the top layer is $\frac {1} {4}$ of the input image for simplicity.</p>
<p><strong>Text detection</strong> This branch is similar to that of [8], where a multi-task prediction is implemented at each spatial location on the top convolutional maps, by adopting an Intersection over Union (IoU) loss described in [34]. It contains two sub-branches on the top convolutional layer designed for joint text/non-text classification and multi-orientation bounding boxes regression. The first sub-branch returns a classification map with an equal spatial size of the top feature maps, indicating the predicted text/non-text probabilities using a softmax function. The second sub-branch outputs five localization maps with the same spatial size, which estimate five parameters for each bounding box with arbitrary orientation at each spatial location of text regions. The five parameters represent the distances of the current point to the top, bottom, left and right sides of an associated bounding box, together with its inclined orientation. With these configurations, the detection branch is able to predict a quadrilateral of arbitrary orientation for each text instance. The feature of the detected quadrilateral region is then feed into the RNN branch for word recognition via a <em>text-alignment</em> layer which is described below.</p>
<h3 id="2-1-Text-Alignment-Layer"><a href="#2-1-Text-Alignment-Layer" class="headerlink" title="2.1. Text-Alignment Layer"></a>2.1. Text-Alignment Layer</h3><p>We create a new recurrent branch for word recognition, where a text-alignment layer is proposed to pre- cisely compute fixed-size convolutional features from a quadrilateral region of arbitrary size. The text-alignment layer is extended from RoI pooling [35] which is widely used for general objects detection. The RoI pooling computes a fixed-size convolutional features (e.g., 7 × 7) from a rectangle region of arbitrary size, by performing quantization operation. It can be integrated into the convolutional layers for in-network region cropping, which is a key component for end-to-end training a detection framework. However, directly applying the RoI pooling to a text region will lead to a significant performance drop in word recognition due to the issue of misalignment.</p>
<p>– First, unlike object detection and classification where the RoI pooling computes global features of a RoI region for discriminating an object, word recognition requires more detailed and accurate local features and spatial information for predicting each character sequentially. As pointed out in [19], the RoI pooling performs quantizations which inevitably introduce misalignments between the original RoI region and the extracted features. Such misalignments have a significant negative effect on predicting characters, particularly on some small-scale ones such as ‘i’, ‘l’.</p>
<ul>
<li>Second, RoI pooling was designed for a rectangle region which is only capable of localizing horizontal instances. It will make larger misalignments when applied to multi-orientation text instances. Furthermore, a large amount of background information and irrelevant texts are easily encoded when a rectangle RoI region is applied to a highly inclined text instance, as shown in Fig. 3. This severely reduces the performance on RNN decoding process for recognizing sequential characters.</li>
</ul>
<p>Recent Mask R-CNN considers explicit per-pixel spatial correspondence by introducing RoIAlign pooling [19]. This inspires current work that develops a new text-alignment layer tailored for text instance which is a quadrilateral shape with arbitrary orientation. It provides strong word-level alignment with accurate per-pixel correspondence, which is of critical importance to extract exact text information from the convolutional maps, as shown in Fig. 3.</p>
]]></content>
    
    <summary type="html">
    
      An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中英文对照
    
    </summary>
    
      <category term="深度学习" scheme="http://noahsnail.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="http://noahsnail.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中文版</title>
    <link href="http://noahsnail.com/2018/06/15/2018-06-15-An%20end-to-end%20TextSpotter%20with%20Explicit%20Alignment%20and%20Attention%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/"/>
    <id>http://noahsnail.com/2018/06/15/2018-06-15-An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中文版/</id>
    <published>2018-06-15T01:51:20.000Z</published>
    <updated>2018-06-21T01:51:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p><strong>声明：作者翻译论文仅为学习，如有侵权请联系作者删除博文，谢谢！</strong></p>
<p>翻译论文汇总：<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank" rel="external">https://github.com/SnailTyan/deep-learning-papers-translation</a></p>
<h1 id="An-end-to-end-TextSpotter-with-Explicit-Alignment-and-Attention"><a href="#An-end-to-end-TextSpotter-with-Explicit-Alignment-and-Attention" class="headerlink" title="An end-to-end TextSpotter with Explicit Alignment and Attention"></a>An end-to-end TextSpotter with Explicit Alignment and Attention</h1>]]></content>
    
    <summary type="html">
    
      An end-to-end TextSpotter with Explicit Alignment and Attention论文翻译——中文版
    
    </summary>
    
      <category term="深度学习" scheme="http://noahsnail.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="http://noahsnail.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>MobileNetV2——Inverted Residuals and Linear Bottlenecks论文翻译——中文版</title>
    <link href="http://noahsnail.com/2018/06/06/2018-06-06-MobileNetV2-%20Inverted%20Residuals%20and%20Linear%20Bottlenecks%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E6%96%87%E7%89%88/"/>
    <id>http://noahsnail.com/2018/06/06/2018-06-06-MobileNetV2- Inverted Residuals and Linear Bottlenecks论文翻译——中文版/</id>
    <published>2018-06-06T07:22:49.000Z</published>
    <updated>2018-07-03T10:15:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p><strong>声明：作者翻译论文仅为学习，如有侵权请联系作者删除博文，谢谢！</strong></p>
<p>翻译论文汇总：<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank" rel="external">https://github.com/SnailTyan/deep-learning-papers-translation</a></p>
<h1 id="MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks"><a href="#MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks" class="headerlink" title="MobileNetV2: Inverted Residuals and Linear Bottlenecks"></a>MobileNetV2: Inverted Residuals and Linear Bottlenecks</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在本文中，我们描述了一种新的移动架构MobileNetV2，该架构提高了移动模型在多个任务和多个基准数据集上以及在不同模型尺寸范围内的最佳性能。我们还描述了在我们称之为SSDLite的新框架中将这些移动模型应用于目标检测的有效方法。此外，我们还演示了如何通过DeepLabv3的简化形式，我们称之为Mobile DeepLabv3来构建移动语义分割模型。</p>
<p>MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性是非常重要的。我们证实了这可以提高性能并提供了产生此设计的直觉。</p>
<p>最后，我们的方法允许将输入/输出域与变换的表现力解耦，这为进一步分析提供了便利的框架。我们在ImageNet[1]分类，COCO目标检测[2]，VOC图像分割[3]上评估了我们的性能。我们评估了在精度、通过乘加（MAdd）度量的操作次数，以及实际的延迟和参数的数量之间的权衡。</p>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>神经网络已经彻底改变了机器智能的许多领域，使具有挑战性的图像识别任务获得了超过常人的准确性。然而，提高准确性的驱动力往往需要付出代价：现代先进网络需要超出许多移动和嵌入式应用能力之外的高计算资源。</p>
<p>本文介绍了一种专为移动和资源受限环境量身定制的新型神经网络架构。我们的网络通过显著减少所需操作和内存的数量，同时保持相同的精度推进了移动定制计算机视觉模型的最新水平。</p>
<p>我们的主要贡献是一个新的层模块：具有线性瓶颈的倒置残差。该模块将输入的低维压缩表示首先扩展到高维并用轻量级深度卷积进行过滤。随后用线性卷积将特征投影回低维表示。官方实现可作为[4]中TensorFlow-Slim模型库的一部分。</p>
<p>这个模块可以使用任何现代框架中的标准操作来高效地实现，并允许我们的模型使用标准基线沿多个性能点击败最先进的技术。此外，这种卷积模块特别适用于移动设计，因为它可以通过从不完全实现大型中间张量来显著减少推断过程中所需的内存占用。这减少了许多嵌入式硬件设计中对主存储器访问的需求，这些设计提供了少量高速软件控制缓存。</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h2><p>调整深层神经架构以在精确性和性能之间达到最佳平衡已成为过去几年研究活跃的一个领域。由许多团队进行的手动架构搜索和训练算法的改进，已经比早期的设计（如AlexNet[5]，VGGNet [6]，GoogLeNet[7]和ResNet[8]）有了显著的改进。最近在算法架构探索方面取得了很多进展，包括超参数优化[9，10，11]、各种网络修剪方法[12，13，14，15，16，17]和连接学习[18，19]。 也有大量的工作致力于改变内部卷积块的连接结构如ShuffleNet[20]或引入稀疏性[21]和其他[22]。</p>
<p>最近，[23,24,25,26]开辟了了一个新的方向，将遗传算法和强化学习等优化方法带入架构搜索。然而，一个缺点是最终所得到的网络非常复杂。在本文中，我们追求的目标是发展了解神经网络如何运行的更好直觉，并使用它来指导最简单可能的网络设计。我们的方法应该被视为[23]中描述的方法和相关工作的补充。在这种情况下，我们的方法与[20，22]所采用的方法类似，并且可以进一步提高性能，同时可以一睹其内部的运行。我们的网络设计基于MobileNetV1[27]。它保留了其简单性，并且不需要任何特殊的运算符，同时显著提高了它的准确性，为移动应用实现了在多种图像分类和检测任务上的最新技术。</p>
<h2 id="3-准备，讨论和直觉"><a href="#3-准备，讨论和直觉" class="headerlink" title="3. 准备，讨论和直觉"></a>3. 准备，讨论和直觉</h2><h3 id="3-1-深度可分卷积"><a href="#3-1-深度可分卷积" class="headerlink" title="3.1. 深度可分卷积"></a>3.1. 深度可分卷积</h3><p>深度可分卷积是许多高效神经网络架构的关键组成部分[27，28，20]，我们在目前的工作中也使用它们。其基本思想是用分解版本替换完整的卷积运算符，将卷积拆分为两个单独的层。第一层称为深度卷积，它通过对每个输入通道应用单个卷积滤波器来执行轻量级滤波。第二层是1×1卷积，称为逐点卷积，它负责通过计算输入通道的线性组合来构建新特征。</p>
<p>标准卷积使用$K\in \mathbf{R}^{k\times k \times d_i \times d_j}$维的输入张量$L_i$，并对其应用卷积核$K\in \mathbf{R}^{k\times k \times d_i \times d_j}$来产生$h_i\times w_i\times d_j$维的输出张量$L_j$。标准卷积层的计算代价为$h_i \cdot w_i \cdot d_i \cdot d_j \cdot k \cdot k$。</p>
<p>深度可分卷积是标准卷积层的直接替换。经验上，它们几乎与常规卷积一样工作，但其成本为：$$\begin{equation}h_i \cdot w_i \cdot d_i (k^2 + d_j) \tag{1}\end{equation}$$它是深度方向和$1\times 1$逐点卷积的总和。深度可分卷积与传统卷积层相比有效地减少了几乎$k^2$倍的计算量。MobileNetV2使用$k=3$（$3\times 3$的深度可分卷积），因此计算成本比标准卷积小$8$到$9$倍，但精度只有很小的降低[27]。</p>
<h3 id="3-2-线性瓶颈"><a href="#3-2-线性瓶颈" class="headerlink" title="3.2. 线性瓶颈"></a>3.2. 线性瓶颈</h3><p>考虑一个由$n$层$L_i$组成的深度神经网络，每层都有一个$h_i \times w_i \times d_i$维的激活张量。在本节中，我们将讨论这些激活张量的基本属性，我们将把它们看作$h_i \times<br>w_i$个具有$d_i$维的“pixels”。非正式地，对于输入的一组真实图像，我们说层激活的集合（对于任何层$L_i$）形成一个“感兴趣的流形”。长久以来，人们一直认为神经网络中的流形可以嵌入到低维子空间中。换句话说，当我们查看深层卷积层的所有单独的$d$通道像素时，在这些值中编码的信息实际上位于某个流形中，这反过来又可嵌入到低维子空间中。</p>
<p>乍一看，这样的实例可以通过简单地减少层的维度来捕获和利用，从而降低操作空间的维度。这已经被MobileNetV1[27]成功利用，通过宽度乘数参数在计算量和精度之间进行有效折衷，并且已经被合并到其他网络的高效模型设计中[20]。遵循这种直觉，宽度乘数方法允许降低激活空间的维度，直到感兴趣的流形横跨整个空间为止。然而，当我们回想到深度卷积神经网络实际上具有非线性的每个坐标变换（例如ReLU）时，这种直觉就会失败。 例如，在1维空间中的一行应用ReLU会产生一个<code>ray</code>，在$\mathbf {R}^n$空间中，它通常会产生一个具有$n$个连接的分段线性曲线。</p>
<p>很容易看出，如果层变换ReLU（Bx）的结果具有非零的体积$S$，映射到内部$S$的点通常通过输入的线性变换$B$获得，因此表明与全维度输出相对应的输入空间的一部分受限于线性变换。换句话说，深层网络只在输出域的非零体积部分具有线性分类器的能力。我们将在补充材料中进行更正式的说明。</p>
<p>另一方面，当ReLU破坏通道时，它不可避免地会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。在补充材料中，我们说明，如果输入流形可以嵌入到激活空间的显著较低维子空间中，则ReLU变换将保留该信息，同时将所需的复杂性引入到可表达的函数集中。</p>
<p>总而言之，我们已经强调了两个特性，这些特性表明需要的感兴趣流行应该位于较高维激活空间的低维子空间中：</p>
<p>1.如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。</p>
<p>2.只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。</p>
<p>这两个深刻见解为我们提供了优化现有神经架构的经验提示：假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。实验证据表明，使用线性层是至关重要的，因为它可以防止非线性破坏太多的信息。在第6节中，我们通过经验证明，在瓶颈中使用非线性层确实会使性能降低几个百分点，进一步证实了我们的假设。我们注意到[29]报告了非线性得到帮助的类似报告，其中非线性已从传统残差块的输入中移除，并导致CIFAR数据集的性能得到了改善。</p>
<p>对于本文的其余部分，我们将利用瓶颈卷积。我们将把输入瓶颈的大小与内部大小之间的比例作为扩展比。</p>
<h3 id="3-3-倒置残差"><a href="#3-3-倒置残差" class="headerlink" title="3.3. 倒置残差"></a>3.3. 倒置残差</h3><p>瓶颈块与残差块类似，其中每个块包含一个输入，然后是几个瓶颈，然后是扩展[8]。然而，受直觉的启发，瓶颈实际上包含所有必要的信息，而扩展层只是伴随张量非线性变换的实现细节，我们直接在瓶颈之间使用快捷连接。图3提供了设计差异的示意图。插入快捷连接的动机与经典的残差连接类似：我们想要提高梯度在乘法层之间传播的能力。但是，倒置设计的内存效率要高得多（详见第5节），而且在我们的实验中效果稍好。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-95ed2cf057e44b0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 3"></p>
<p>图3：残差块[8，30]和倒置残差之间的差异。对角阴影线层不使用非线性。我们用每个块的厚度来表明其相对数量的通道。注意经典残差是如何将通道数量较多的层连接起来的，而倒置残差则是连接瓶颈。最好通过颜色看。</p>
<p><strong>瓶颈卷积的运行时间和参数计数</strong>基本实现结构如表1所示。对于大小为$h\times w$的块，扩展因子为$t$，内核大小为$k$，具有$d’$维输入通道和$d’’$维输出通道，所需的乘法加法总数为$h \cdot w \cdot d’ \cdot t(d’ + k^2 + d’’)$。与（1）相比，这个表达式有一个额外项，因为实际上我们有一个额外的1×1卷积，但是我们的网络性质使我们能够利用更小的输入和输出维度。在表3中，我们比较了MobileNetV1，MobileNetV2和ShuffleNet之间每种分辨率所需的尺寸。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-d6617f4ac1167d47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 1"></p>
<p>表1：瓶颈残差块从$k$转换为$k’$个通道，步长为$s$，扩展系数为$t$。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-04f2dcd1a1cea319.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 3"></p>
<p>表3：不同架构中需要在每个空间分辨率上实现的最大通道数/内存（以Kb为单位）。我们假设激活使用16位浮点数。对于ShuffleNet，我们使用与MobileNetV1和MobileNetV2的性能相匹配的$2x，g = 3 $。对于MobileNetV2和ShuffleNet的第一层，我们可以采用第5节中描述的技巧来降低内存需求。尽管ShuffleNet在其它地方使用了瓶颈，但由于存在非瓶颈张量之间的快捷连接，因此非瓶颈张量仍然需要实现。</p>
<h3 id="3-4-信息流解释"><a href="#3-4-信息流解释" class="headerlink" title="3.4. 信息流解释"></a>3.4. 信息流解释</h3><p>我们架构的一个有趣特性是它在构建块（瓶颈层）的输入/输出域与层转换之间提供了自然分离——这是一种将输入转换为输出的非线性函数。前者可以看作是网络在每一层的容量，而后者则是表现力。与常规和可分离的传统卷积块相比，其中表现力和容量都缠结在一起并且是输出层深度的函数。</p>
<p>特别是在我们的实例中，当内层深度为0时，由于快捷连接，基础卷积是恒等函数。当扩展比率小于1时，这是一个经典的残差卷积块[8，30]。但是，就我们的目的而言，我们表明扩大比率大于1是最有用的。</p>
<p>这种解释使我们能够独立于其容量研究网络的表现力，并且我们认为需要进一步探索这种分离，以便更好地理解网络性质。</p>
<h2 id="4-模型架构"><a href="#4-模型架构" class="headerlink" title="4. 模型架构"></a>4. 模型架构</h2><p>现在我们详细描述我们的架构。正如前一节所讨论的那样，基本构件块是一个瓶颈深度可分离的残差卷积。该模块的详细结构如表1所示。MobileNetV2的架构包含具有32个滤波器的初始全卷积层，接着是表2中描述的19个残差瓶颈层。我们使用ReLU6作为非线性，因为用于低精度计算时它的鲁棒性[27]。我们总是使用现代网络中的标准核尺寸3×3，并在训练期间利用丢弃和批归一化。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-7c24424dcf9e2997.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 2"></p>
<p>表2：MobileNetV2：每行描述一个或多个相同（模步长）层的序列，重复$n$次。同一序列中的所有图层具有相同数量的$c$个输出通道。每个序列的第一层有一个步长$s$，所有其他的都使用长$1$。所有空间卷积使用3×3的核。扩展系数$t$总是应用于输入尺寸，如表1所述。</p>
<p>除第一层外，我们在整个网络中使用恒定的扩展率。在我们的实验中，我们发现5到10之间的扩展速率导致几乎相同的性能曲线，较小的网络以较小的扩展速率更好，而较大的网络在较大扩展速率时具有稍微更好的性能。</p>
<p>对于我们所有的主要实验，我们使用扩展因子$6$来应用于输入张量的大小。例如，对于瓶颈层采用$64$通道的输入张量并产生具有$128$通道的张量，中间扩展层则具有$64·6 =384$个通道。</p>
<p>和[27]一样，我们通过使用输入图像分辨率和宽度倍数作为可调超参数来调整我们的架构以适应不同的性能点，可以根据所需的精度/性能权衡来调整。我们的主要网络（宽度乘数1，224×224）的计算成本为3亿次乘法，并使用了340万个参数。我们研究了性能权衡，输入分辨率从96到224，宽度乘数从0.35到1.4。网络计算成本范围从7次乘法增加到585M MAdds，而模型大小在1.7M个参数和6.9M个参数之间变化。</p>
<p>一个较小的实现差异，[27]是对于小于1的乘数，我们将宽度乘数应用于除最后一个卷积层以外的所有层。这可以提高更小模型的性能。</p>
<h2 id="5-实现说明"><a href="#5-实现说明" class="headerlink" title="5. 实现说明"></a>5. 实现说明</h2><h3 id="5-1-内存有效推断"><a href="#5-1-内存有效推断" class="headerlink" title="5.1. 内存有效推断"></a>5.1. 内存有效推断</h3><p>倒置的残差颈层允许特定地内存有效的实现，这对于移动应用非常重要。使用TensorFlow[31]或Caffe[32]等标准高效的推断实现，构建了一个有向无环计算超图$G$，由表示操作的边和代表中间计算张量的节点组成。预定计算是为了最小化需要存储在内存中的张量总数。在最一般的情况下，它会搜索所有合理的计算顺序$\Sigma (G)$，并选择最小化$$ M(G) = \min_{\pi\in \Sigma(G)} \max_{i \in 1..n} \left[\sum_{A \in R(i, \pi, G)} |A|\right] + \text{size}(\pi_i)$$。$$其中$R(i, \pi, G)$是连接到任何$\pi_{i}\dots \pi_{n}$节点的中间张量列表，$|A|$表示张量$A$的大小，$size(i)$是操作$i$期间内部存储所需的总内存量。</p>
<p>对于仅具有平凡并行结构（例如残差连接）的图，只有一个非平凡的可行计算顺序，因此可以简化计算图$G$推断所需的内存总量和界限：$$M(G) = \max_{op \in G} \left[\sum_{A \in \text{op}_{inp}} |A| + \sum_{B \in \text{op}_{out}} |B| + |op|\right] \tag {2}$$或者重申，内存量只是在所有操作中组合输入和输出的最大总大小。在下文中我们将展示如果我们将瓶颈残差块视为单一操作（并将内部卷积视为一次性张量），则总内存量将由瓶颈张量的大小决定，而不是瓶颈的内部张量的大小（更大）。</p>
<p><strong>瓶颈残差块</strong> 图3b中所示的$\mathcal{F}(x)$可以表示为三个运算符的组合$\mathcal{F}(x) = [A \circ \mathcal{N} \circ  B] x$，其中$A$是线性变换$A:\mathcal{R}^{s \times s \times k} \rightarrow \mathcal{R}^{s \times s \times n}$，$\mathcal{N}$是一个非线性的每个通道的转换：$\mathcal{N}: \mathcal{R}^{s \times s \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times n}$，$B$是输出域的线性转换：$B: \mathcal{R}^{s’ \times s’ \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times k’}$。</p>
<p>对于我们的网络$\mathcal{N} = ReLU6 \circ dwise \circ ReLU6$，但结果适用于任何的按通道转换。假设输入域的大小是$|x|$并且输出域的大小是$|y|$，那么计算$F(X)$所需的内存可以低至$|s^2 k| + |s’^2 k’| + O(\max(s^2, s’^2))$。</p>
<p>该算法基于以下事实：内部张量$\cal I$可以表示为$t$张量的连接，每个大小为$n/t$，则我们的函数可以表示为$$\mathcal{F}(x) = \sum_{i=1}^t (A_i \circ N \circ B_i)(x)$$通过累加和，我们只需要将一个大小为$n/t$的中间块始终保留在内存中。使用$n=t$，我们最终只需要保留中间表示的单个通道。使我们能够使用这一技巧的两个约束是（a）内部变换（包括非线性和深度）是每个通道的事实，以及（b）连续的非按通道运算符具有显著的输入输出大小比。对于大多数传统的神经网络，这种技巧不会产生显著的改善。</p>
<p>我们注意到，使用$t$路分割计算$F(X)$所需的乘加运算符的数目是独立于$t$的，但在现有实现中，我们发现由于增加的缓存未命中，用几个较小的矩阵乘法替换一个矩阵乘法会很损坏运行时的性能 。我们发现这种方法最有用，$t$是$2$和$5$之间的一个小常数。它显著降低了内存需求，但仍然可以利用深度学习框架提供的高度优化的矩阵乘法和卷积算子来获得的大部分效率。如果特殊的框架级优化可能导致进一步的运行时改进，这个方法还有待观察。</p>
<h2 id="6-实验"><a href="#6-实验" class="headerlink" title="6. 实验"></a>6. 实验</h2><h3 id="6-1-ImageNet分类"><a href="#6-1-ImageNet分类" class="headerlink" title="6.1. ImageNet分类"></a>6.1. ImageNet分类</h3><p><strong>训练设置</strong>我们使用TensorFlow[31]训练我们的模型。我们使用标准的RMSPropOptimizer，将衰减和动量都设置为0.9。我们在每层之后使用批标准化，并将标准权重衰减设置为0.00004。遵循MobileNetV1 [27]的设置，我们使用初始学习率为0.045，学习率的衰减比率为每个迭代周期衰减0.98。我们使用16个GPU异步，批大小为96。</p>
<p><strong>结果</strong>我们将我们的网络与MobileNetV1，ShuffleNet和NASNet-A模型进行了比较。表4列出了一些选定模型的统计数据，完整的性能图如图5所示。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-411f1873403d0fca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 4"></p>
<p>表4：比较不同网络在ImageNet上的性能。正如ops的常见做法一样，我们计算Multiply-Adds的总数。在最后一列中，我们报告了Google Pixel 1手机上的一个大型核心（使用TF-Lite）的运行时间，以毫秒（ms）为单位。我们不报告ShuffleNet的数字，因为高效的群组卷积和混排尚未支持。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-e54b02e9564b2f01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 5"></p>
<p>图5：MobileNetV2与MobileNetV1，ShuffleNet，NAS的性能曲线。对于我们的网络，我们对所有分辨率使用乘数0.35，0.5，0.75，1.0，对于分辨率为224，我们使用乘数1.4。</p>
<h3 id="6-2-目标检测"><a href="#6-2-目标检测" class="headerlink" title="6.2. 目标检测"></a>6.2. 目标检测</h3><p>我们评估和比较了MobileNetV2和MobileNetV1的性能，MobileNetV1使用COCO数据集[2]上Single Shot Detector（SSD）[34]的修改版本作为目标检测的特征提取器[33]。我们还将YOLOv2[35]和原始SSD（以VGG-16[6]为基础网络）作为基准进行比较。由于我们专注于移动/实时模型，因此我们不会比较Faster-RCNN[36]和RFCN[37]等其它架构的性能。</p>
<p><strong>SSDLite</strong> 在本文中，我们将介绍常规SSD的移动友好型变种。我们在SSD预测层中用可分离卷积（深度方向后接$1\times 1$投影）替换所有常规卷积。这种设计符合MobileNets的整体设计，并且在计算上效率更高。我们称之为修改版本的SSDLite。与常规SSD相比，SSDLite显著降低了参数计数和计算成本，如表5所示。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-85996725f1f95a1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 5"></p>
<p>表5：使用MobileNetV2配置的SSD和SSDLite之间的大小和计算成本以及对80个类进行预测的比较。</p>
<p>对于MobileNetV1，我们按照[33]中的设置进行。对于MobileNetV2，SSDLite的第一层被附加到层15的扩展（输出步长为16）。SSDLite层的第二层和其余层连接在最后一层的顶部（输出步长为32）。此设置与MobileNetV1一致，因为所有层都附加到相同输出步长的特征图上。</p>
<p>MobileNet模型都经过了开源TensorFlow目标检测API的训练和评估[38]。 两个模型的输入分辨率为$320 \times 320$。我们进行了基准测试并比较了mAP（COCO挑战度量标准），参数数量和Multiply-Adds数量。结果如表6所示。MobileNetV2 SSDLite不仅是最高效的模型，而且也是三者中最准确的模型。值得注意的是，MobileNetV2 SSDLite效率高20倍，模型要小10倍，但仍优于COCO数据集上的YOLOv2。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-f9daccb9ae7d1cc9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 6"></p>
<p>表6：MobileNetV2+SSDLite和其他实时检测器在COCO数据集目标检测任务中的性能比较。MobileNetV2+SSDLite以更少的参数和更小的计算复杂性实现了具有竞争力的精度。所有模型都在<code>trainval35k</code>上进行训练，并在<code>test-dev</code>上进行评估。SSD/YOLOv2的数字来自于[35]。使用内部版本的TF-Lite引擎，报告了在Google Pixel 1手机的大型核心上的运行时间。</p>
<h3 id="6-3-语义分割"><a href="#6-3-语义分割" class="headerlink" title="6.3. 语义分割"></a>6.3. 语义分割</h3><p>在本节中，我们使用MobileNetV1和MobileNetV2模型作为特征提取器与DeepLabv3[39]在移动语义分割任务上进行比较。DeepLabv3采用了空洞卷积[40,41,42]，这是一种显式控制计算特征映射分辨率的强大工具，并构建了五个平行头部，包括（a）包含三个具有不同空洞率的$3 \times 3$卷积的Atrous Spatial Pyramid Pooling模块(ASPP)[43]，（b）$1 \times 1$卷积头部，以及（c）图像级特征[44]。我们用输出步长来表示输入图像空间分辨率与最终输出分辨率的比值，该分辨率通过适当地应用空洞卷积来控制。对于语义分割，我们通常使用输出$stride = 16$或$8$来获取更密集的特征映射。我们在PASCAL VOC 2012数据集[3]上进行了实验，使用[45]中的额外标注图像和评估指标mIOU。</p>
<p>为了构建移动模型，我们尝试了三种设计变体：（1）不同的特征提取器，（2）简化DeepLabv3头部以加快计算速度，以及（3）提高性能的不同推断策略。我们的结果总结在表7中。我们已经观察到：（a）包括多尺度输入和添加左右翻转图像的推断策略显著增加了MAdds，因此不适合于在设备上应用，（b）使用输出步长16比使用输出步长8更有效率，（c）MobileNetV1已经是一个强大的特征提取器，并且只需要比ResNet-101少约4.9-5.7倍的MAdd[8]（例如，mIOU：78.56与82.70和MAdds：941.9B vs 4870.6B），（d）在MobileNetV2的倒数第二个特征映射的顶部构建DeepLabv3头部比在原始的最后一个特征映射上更高效，因为倒数第二个特征映射包含320个通道而不是1280个通道，这样我们就可以达到类似的性能，但是要比MobileNetV1的通道少2.5倍，（e）DeepLabv3头部的计算成本很高，移除ASPP模块会显著减少MAdd并且只会稍微降低性能。在表7末尾，我们鉴定了一个设备上的潜在候选应用（粗体），该应用可以达到$75.32\%$mIOU并且只需要2.75B MAdds。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-a62e21b1f981dbb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 7"></p>
<p>表7：PASCAL VOC 2012验证集上的MobileNet+DeepLabv3推断策略。MNet V2*：用于DeepLabv3头部的倒数第二个特征映射，其中包括（1）Atrous Spatial Pyramid Pooling（ASPP）模块和（2）$1\times 1$卷积以及图像池化功能。OS：控制分割映射输出分辨率的输出步长。MF：测试期间多尺度和左右翻转输入。所有的模型都在COCO上进行预训练。设备上的潜在候选应用以粗体显示。PASCAL图像的尺寸为$ 512 \ times 512 $，而空洞卷积使得我们可以在不增加参数数量的情况下控制输出特征分辨率。</p>
<h3 id="6-4-消融研究"><a href="#6-4-消融研究" class="headerlink" title="6.4. 消融研究"></a>6.4. 消融研究</h3><p><strong>倒置残差连接</strong>。残差连接的重要性已被广泛研究[8，30，46]。本文报告的新结果是连接瓶颈的快捷连接性能优于连接扩展层的的快捷连接（请参见图6b以供比较）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-51a75c72154fa734.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 6"></p>
<p>图6：非线性和各种快捷（残差）连接的影响。</p>
<p><strong>线性瓶颈</strong>的重要性。线性瓶颈模型的严格来说比非线性模型要弱一些，因为激活总是可以在线性状态下进行，并对偏差和缩放进行适当的修改。然而，我们在图6a中展示的实验表明，线性瓶颈改善了性能，为非线性破坏低维空间中的信息提供了支持。</p>
<h2 id="7-总结及将来工作"><a href="#7-总结及将来工作" class="headerlink" title="7. 总结及将来工作"></a>7. 总结及将来工作</h2><p>我们描述了一个非常简单的网络架构，使我们能够构建一系列高效的移动模型。我们的基本构建单元具有多种特性，使其特别适用于移动应用。它允许非常有效的内存推断，并依赖利用所有神经框架中的标准操作。</p>
<p>对于ImageNet数据集，我们的架构改善了许多性能点的最新技术水平。对于目标检测任务，我们的网络在精度和模型复杂度方面都优于COCO数据集上的最新实时检测器。值得注意的是，我们的架构与SSDLite检测模块相比，计算量少20倍，参数比YOLOv2少10倍。</p>
<p>理论上：所提出的卷积块具有独特的属性，允许将网络表现力（由扩展层编码）与其容量（由瓶颈输入编码）分开。探索这个是未来研究的重要方向。</p>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>我们要感谢Matt Streeter和Sergey Ioffe的有益反馈和讨论。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. Int. J. Comput. Vision, 115(3):211–252, December 2015.</p>
<p>[2] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV, 2014.</p>
<p>[3] Mark Everingham, S. M. Ali Eslami, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserma. The pascal visual object classes challenge a retrospective. IJCV, 2014.</p>
<p>[4] Mobilenetv2 source code. Available from <a href="https://github.com/tensorflow/" target="_blank" rel="external">https://github.com/tensorflow/</a> models/tree/master/research/slim/nets/mobilenet.</p>
<p>[5] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Bartlett et al. [48], pages 1106–1114.</p>
<p>[6] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.</p>
<p>[7] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015, pages 1–9. IEEE Computer Society, 2015.</p>
<p>[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.</p>
<p>[9] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13:281–305, 2012.</p>
<p>[10] Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine learning algorithms. In Bartlett et al. [48], pages 2960–2968.</p>
<p>[11] Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md. Mostofa Ali Patwary, Prabhat, and Ryan P. Adams. Scalable bayesian optimization using deep neural networks. In Francis R. Bach and David M. Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR Workshop and Conference Proceedings, pages 2171–2180. JMLR.org, 2015.</p>
<p>[12] Babak Hassibi and David G. Stork. Second order derivatives for network pruning: Optimal brain surgeon. In Stephen Jose Hanson, Jack D. Cowan, and C. Lee Giles, editors, Advances in Neural Information Processing Systems 5, [NIPS Conference, Denver, Colorado, USA, November 30 - December 3, 1992], pages 164–171. Morgan Kaufmann, 1992.</p>
<p>[13] Yann LeCun, John S. Denker, and Sara A. Solla. Optimal brain damage. In David S. Touretzky, editor, Advances in Neural Information Processing Systems 2, [NIPS Conference, Denver, Colorado, USA, November 27-30, 1989], pages 598–605. Morgan Kaufmann, 1989.</p>
<p>[14] Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights and connections for efficient neural network. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 1135–1143, 2015.</p>
<p>[15] Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Shijian Tang, Erich Elsen, Bryan Catanzaro, John Tran, and William J. Dally. DSD: regularizing deep neural networks with dense-sparse-dense training flow. CoRR, abs/1607.04381, 2016.</p>
<p>[16] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 1379–1387, 2016.</p>
<p>[17] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. CoRR, abs/1608.08710, 2016.</p>
<p>[18] Karim Ahmed and Lorenzo Torresani. Connectivity learning in multi-branch networks. CoRR, abs/1709.09582, 2017.</p>
<p>[19] Tom Veniat and Ludovic Denoyer. Learning time-efficient deep architectures with budgeted super networks. CoRR, abs/1706.00046, 2017.</p>
<p>[20] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CoRR, abs/1707.01083, 2017.</p>
<p>[21] Soravit Changpinyo, Mark Sandler, and Andrey Zhmoginov. The power of sparsity in convolutional neural networks. CoRR, abs/1702.06257, 2017.</p>
<p>[22] Min Wang, Baoyuan Liu, and Hassan Foroosh. Design of efficient convolutional layers using single intra-channel convolution, topological subdivisioning and spatial ”bottleneck” structure. CoRR, abs/1608.04337, 2016.</p>
<p>[23] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. Learning transferable architectures for scalable image recognition. CoRR, abs/1707.07012, 2017.</p>
<p>[24] Lingxi Xie and Alan L. Yuille. Genetic CNN. CoRR, abs/1703.01513, 2017.</p>
<p>[25] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V. Le, and Alexey Kurakin. Large-scale evolution of image classifiers. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 2902–2911. PMLR, 2017.</p>
<p>[26] Barret Zoph and Quoc V. Le. Neural architecture search with reinforcement learning. CoRR, abs/1611.01578, 2016.</p>
<p>[27] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam.<br>Mobilenets: Efficient convolutional neural networks for mobile vision applications. CoRR, abs/1704.04861, 2017.</p>
<p>[28] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.</p>
<p>[29] Dongyoon Han, Jiwhan Kim, and Junmo Kim. Deep pyramidal residual networks. CoRR, abs/1610.02915, 2016.</p>
<p>[30] Saining Xie, Ross B. Girshick, Piotr Dolla ́r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. CoRR, abs/1611.05431, 2016.</p>
<p>[31] Martın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.</p>
<p>[32] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embed- ding. arXiv preprint arXiv:1408.5093, 2014.</p>
<p>[33] Jonathan Huang, Vivek Rathod, Chen Sun, Men- glong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, et al. Speed/accuracy trade-offs for modern convolutional object detectors. In CVPR, 2017.</p>
<p>[34] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In ECCV, 2016.</p>
<p>[35] Joseph Redmon and Ali Farhadi. Yolo9000: Better, faster, stronger. arXiv preprint arXiv:1612.08242, 2016.</p>
<p>[36] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015.</p>
<p>[37] Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. R-fcn: Object detection via region-based fully convolutional networks. In Advances in neural information processing systems, pages 379–387, 2016.</p>
<p>[38] Jonathan Huang, Vivek Rathod, Derek Chow, Chen Sun, and Menglong Zhu. Tensorflow object detection api, 2017.</p>
<p>[39] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. CoRR, abs/1706.05587, 2017.</p>
<p>[40] Matthias Holschneider, Richard Kronland-Martinet, Jean Morlet, and Ph Tchamitchian. A real-time algorithm for signal analysis with the help of the wavelet transform. In Wavelets: Time-Frequency Methods and Phase Space, pages 289–297. 1989.</p>
<p>[41] Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu, Rob Fergus, and Yann LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. arXiv:1312.6229, 2013.</p>
<p>[42] George Papandreou,Iasonas Kokkinos, and Pierre Andre Savalle. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection. In CVPR, 2015.</p>
<p>[43] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. TPAMI, 2017.</p>
<p>[44] Wei Liu, Andrew Rabinovich, and Alexander C. Berg. Parsenet: Looking wider to see better. CoRR, abs/1506.04579, 2015.</p>
<p>[45] Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In ICCV, 2011.</p>
<p>[46] Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016.</p>
<p>[47] Guido Montúfar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS’14, pages 2924–2932, Cambridge, MA, USA, 2014. MIT Press.</p>
<p>[48] Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, Léon Bottou, and Kilian Q. Weinberger, editors. Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States, 2012.</p>
]]></content>
    
    <summary type="html">
    
      MobileNetV2——Inverted Residuals and Linear Bottlenecks论文翻译——中文版
    
    </summary>
    
      <category term="深度学习" scheme="http://noahsnail.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="http://noahsnail.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>MobileNetV2——Inverted Residuals and Linear Bottlenecks论文翻译——中英文对照</title>
    <link href="http://noahsnail.com/2018/06/06/2018-06-06-MobileNetV2-%20Inverted%20Residuals%20and%20Linear%20Bottlenecks%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AF%B9%E7%85%A7/"/>
    <id>http://noahsnail.com/2018/06/06/2018-06-06-MobileNetV2- Inverted Residuals and Linear Bottlenecks论文翻译——中英文对照/</id>
    <published>2018-06-06T07:22:11.000Z</published>
    <updated>2018-07-04T01:31:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p><strong>声明：作者翻译论文仅为学习，如有侵权请联系作者删除博文，谢谢！</strong></p>
<p>翻译论文汇总：<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank" rel="external">https://github.com/SnailTyan/deep-learning-papers-translation</a></p>
<h1 id="MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks"><a href="#MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks" class="headerlink" title="MobileNetV2: Inverted Residuals and Linear Bottlenecks"></a>MobileNetV2: Inverted Residuals and Linear Bottlenecks</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3.</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在本文中，我们描述了一种新的移动架构MobileNetV2，该架构提高了移动模型在多个任务和多个基准数据集上以及在不同模型尺寸范围内的最佳性能。我们还描述了在我们称之为SSDLite的新框架中将这些移动模型应用于目标检测的有效方法。此外，我们还演示了如何通过DeepLabv3的简化形式，我们称之为Mobile DeepLabv3来构建移动语义分割模型。</p>
<p>The MobileNetV2 architecture is based on an inverted residual structure where the shortcut connections are between the thin bottle-neck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design.</p>
<p>MobileNetV2架构基于倒置的残差结构，其中快捷连接位于窄的瓶颈层之间。中间展开层使用轻量级的深度卷积作为非线性源来过滤特征。此外，我们发现为了保持表示能力，去除窄层中的非线性是非常重要的。我们证实了这可以提高性能并提供了产生此设计的直觉。</p>
<p>Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.</p>
<p>最后，我们的方法允许将输入/输出域与变换的表现力解耦，这为进一步分析提供了便利的框架。我们在ImageNet[1]分类，COCO目标检测[2]，VOC图像分割[3]上评估了我们的性能。我们评估了在精度、通过乘加（MAdd）度量的操作次数，以及实际的延迟和参数的数量之间的权衡。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>Neural networks have revolutionized many areas of machine intelligence, enabling superhuman accuracy for challenging image recognition tasks. However, the drive to improve accuracy often comes at a cost: modern state of the art networks require high computational resources beyond the capabilities of many mobile and embedded applications.</p>
<h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>神经网络已经彻底改变了机器智能的许多领域，使具有挑战性的图像识别任务获得了超过常人的准确性。然而，提高准确性的驱动力往往需要付出代价：现代先进网络需要超出许多移动和嵌入式应用能力之外的高计算资源。</p>
<p>This paper introduces a new neural network architecture that is specifically tailored for mobile and resource constrained environments. Our network pushes the state of the art for mobile tailored computer vision models, by significantly decreasing the number of operations and memory needed while retaining the same accuracy.</p>
<p>本文介绍了一种专为移动和资源受限环境量身定制的新型神经网络架构。我们的网络通过显著减少所需操作和内存的数量，同时保持相同的精度推进了移动定制计算机视觉模型的最新水平。</p>
<p>Our main contribution is a novel layer module: the inverted residual with linear bottleneck. This module takes as an input a low-dimensional compressed representation which is first expanded to high dimension and filtered with a lightweight depthwise convolution. Features are subsequently projected back to a low-dimensional representation with a linear convolution. The official implementation is available as part of TensorFlow-Slim model library in [4].</p>
<p>我们的主要贡献是一个新的层模块：具有线性瓶颈的倒置残差。该模块将输入的低维压缩表示首先扩展到高维并用轻量级深度卷积进行过滤。随后用线性卷积将特征投影回低维表示。官方实现可作为[4]中TensorFlow-Slim模型库的一部分。</p>
<p>This module can be efficiently implemented using standard operations in any modern framework and allows our models to beat state of the art along multiple performance points using standard benchmarks. Furthermore, this convolutional module is particularly suitable for mobile designs, because it allows to significantly reduce the memory footprint needed during inference by never fully materializing large intermediate tensors. This reduces the need for main memory access in many embedded hardware designs, that provide small amounts of very fast software controlled cache memory.</p>
<p>这个模块可以使用任何现代框架中的标准操作来高效地实现，并允许我们的模型使用标准基线沿多个性能点击败最先进的技术。此外，这种卷积模块特别适用于移动设计，因为它可以通过从不完全实现大型中间张量来显著减少推断过程中所需的内存占用。这减少了许多嵌入式硬件设计中对主存储器访问的需求，这些设计提供了少量高速软件控制缓存。</p>
<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p>Tuning deep neural architectures to strike an optimal balance between accuracy and performance has been an area of active research for the last several years. Both manual architecture search and improvements in training algorithms, carried out by numerous teams has lead to dramatic improvements over early designs such as AlexNet [5], VGGNet [6], GoogLeNet [7]. , and ResNet [8]. Recently there has been lots of progress in algorithmic architecture exploration included hyper-parameter optimization [9, 10, 11] as well as various methods of network pruning [12, 13, 14, 15, 16, 17] and connectivity learning [18, 19]. A substantial amount of work has also been dedicated to changing the connectivity structure of the internal convolutional blocks such as in ShuffleNet [20] or introducing sparsity [21] and others [22].</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h2><p>调整深层神经架构以在精确性和性能之间达到最佳平衡已成为过去几年研究活跃的一个领域。由许多团队进行的手动架构搜索和训练算法的改进，已经比早期的设计（如AlexNet[5]，VGGNet [6]，GoogLeNet[7]和ResNet[8]）有了显著的改进。最近在算法架构探索方面取得了很多进展，包括超参数优化[9，10，11]、各种网络修剪方法[12，13，14，15，16，17]和连接学习[18，19]。 也有大量的工作致力于改变内部卷积块的连接结构如ShuffleNet[20]或引入稀疏性[21]和其他[22]。</p>
<p>Recently, [23, 24, 25, 26], opened up a new direction of bringing optimization methods including genetic algorithms and reinforcement learning to architectural search. However one drawback is that the resulting networks end up very complex. In this paper, we pursue the goal of developing better intuition about how neural networks operate and use that to guide the simplest possible network design. Our approach should be seen as complimentary to the one described in [23] and related work. In this vein our approach is similar to those taken by [20, 22] and allows to further improve the performance, while providing a glimpse on its internal operation. Our network design is based on MobileNetV1 [27]. It retains its simplicity and does not require any special operators while significantly improves its accuracy, achieving state of the art on multiple image classification and detection tasks for mobile applications.</p>
<p>最近，[23,24,25,26]开辟了了一个新的方向，将遗传算法和强化学习等优化方法带入架构搜索。然而，一个缺点是最终所得到的网络非常复杂。在本文中，我们追求的目标是发展了解神经网络如何运行的更好直觉，并使用它来指导最简单可能的网络设计。我们的方法应该被视为[23]中描述的方法和相关工作的补充。在这种情况下，我们的方法与[20，22]所采用的方法类似，并且可以进一步提高性能，同时可以一睹其内部的运行。我们的网络设计基于MobileNetV1[27]。它保留了其简单性，并且不需要任何特殊的运算符，同时显著提高了它的准确性，为移动应用实现了在多种图像分类和检测任务上的最新技术。</p>
<h2 id="3-Preliminaries-discussion-and-intuition"><a href="#3-Preliminaries-discussion-and-intuition" class="headerlink" title="3. Preliminaries, discussion and intuition"></a>3. Preliminaries, discussion and intuition</h2><h3 id="3-1-Depthwise-Separable-Convolutions"><a href="#3-1-Depthwise-Separable-Convolutions" class="headerlink" title="3.1. Depthwise Separable Convolutions"></a>3.1. Depthwise Separable Convolutions</h3><p>Depthwise Separable Convolutions are a key building block for many efficient neural network architectures [27, 28, 20] and we use them in the present work as well. The basic idea is to replace a full convolutional operator with a factorized version that splits convolution into two separate layers. The first layer is called a depthwise convolution, it performs lightweight filtering by applying a single convolutional filter per input channel. The second layer is a 1 × 1 convolution, called a pointwise convolution, which is responsible for building new features through computing linear combinations of the input channels.</p>
<h2 id="3-准备，讨论和直觉"><a href="#3-准备，讨论和直觉" class="headerlink" title="3. 准备，讨论和直觉"></a>3. 准备，讨论和直觉</h2><h3 id="3-1-深度可分卷积"><a href="#3-1-深度可分卷积" class="headerlink" title="3.1. 深度可分卷积"></a>3.1. 深度可分卷积</h3><p>深度可分卷积是许多高效神经网络架构的关键组成部分[27，28，20]，我们在目前的工作中也使用它们。其基本思想是用分解版本替换完整的卷积运算符，将卷积拆分为两个单独的层。第一层称为深度卷积，它通过对每个输入通道应用单个卷积滤波器来执行轻量级滤波。第二层是1×1卷积，称为逐点卷积，它负责通过计算输入通道的线性组合来构建新特征。</p>
<p>Standard convolution takes an $h_i\times w_i\times d_i$ input tensor $L_i$, and applies convolutional  kernel $K\in \mathbf{R}^{k\times k \times d_i \times d_j}$ to produce an $h_i\times w_i\times d_j$ output tensor $L_j$. Standard convolutional layers have the computational cost of $h_i \cdot w_i \cdot d_i \cdot d_j \cdot k \cdot k$.</p>
<p>标准卷积使用$K\in \mathbf{R}^{k\times k \times d_i \times d_j}$维的输入张量$L_i$，并对其应用卷积核$K\in \mathbf{R}^{k\times k \times d_i \times d_j}$来产生$h_i\times w_i\times d_j$维的输出张量$L_j$。标准卷积层的计算代价为$h_i \cdot w_i \cdot d_i \cdot d_j \cdot k \cdot k$。</p>
<p>Depthwise separable convolutions are a drop-in replacement for standard convolutional layers. Empirically they work almost as well as regular convolutions but only cost: $$\begin{equation}h_i \cdot w_i \cdot d_i (k^2 + d_j) \tag{1}\end{equation}$$ which is the sum of the depthwise and $1 \times 1$ pointwise convolutions. Effectively depthwise separable convolution reduces computation compared to traditional layers by almost a factor of $k^2$. MobileNetV2 uses $k=3$ ($3 \times 3$ depthwise separable convolutions) so the computational cost is $8$ to $9$ times smaller than that of standard convolutions at only a small reduction in accuracy [27].</p>
<p>深度可分卷积是标准卷积层的直接替换。经验上，它们几乎与常规卷积一样工作，但其成本为：$$\begin{equation}h_i \cdot w_i \cdot d_i (k^2 + d_j) \tag{1}\end{equation}$$它是深度方向和$1\times 1$逐点卷积的总和。深度可分卷积与传统卷积层相比有效地减少了几乎$k^2$倍的计算量。MobileNetV2使用$k=3$（$3\times 3$的深度可分卷积），因此计算成本比标准卷积小$8$到$9$倍，但精度只有很小的降低[27]。</p>
<h3 id="3-2-Linear-Bottlenecks"><a href="#3-2-Linear-Bottlenecks" class="headerlink" title="3.2. Linear Bottlenecks"></a>3.2. Linear Bottlenecks</h3><p>Consider a deep neural network consisting of $n$ layers $L_i$ each of which has an activation tensor of dimensions $h_i \times w_i \times d_i$. Throughout this section we will be discussing the basic properties of these activation tensors, which we will treat as containers of $h_i \times<br>w_i$ “pixels” with $d_i$ dimensions. Informally, for an input set of real images, we say that the set of layer activations (for any layer $L_i$) forms a “manifold of interest”. It has been long assumed that manifolds of interest in neural networks could be embedded in low-dimensional subspaces. In other words, when we look at all individual $d$-channel pixels of a deep convolutional layer, the information encoded in those values actually lie in some manifold, which in turn is embeddable into a low-dimensional subspace.</p>
<h3 id="3-2-线性瓶颈"><a href="#3-2-线性瓶颈" class="headerlink" title="3.2. 线性瓶颈"></a>3.2. 线性瓶颈</h3><p>考虑一个由$n$层$L_i$组成的深度神经网络，每层都有一个$h_i \times w_i \times d_i$维的激活张量。在本节中，我们将讨论这些激活张量的基本属性，我们将把它们看作$h_i \times<br>w_i$个具有$d_i$维的“pixels”。非正式地，对于输入的一组真实图像，我们说层激活的集合（对于任何层$L_i$）形成一个“感兴趣的流形”。长久以来，人们一直认为神经网络中的流形可以嵌入到低维子空间中。换句话说，当我们查看深层卷积层的所有单独的$d$通道像素时，在这些值中编码的信息实际上位于某个流形中，这反过来又可嵌入到低维子空间中。</p>
<p>At a first glance, such a fact could then be captured and exploited by simply reducing the dimensionality of a layer thus reducing the dimensionality of the operating space. This has been successfully exploited by MobileNetV1 [27] to effectively trade off between computation and accuracy via a width multiplier parameter, and has been incorporated into efficient model designs of other networks as well [20]. Following that intuition, the width multiplier approach allows one to reduce the dimensionality of the activation space until the manifold of interest spans this entire space. However, this intuition breaks down when we recall that deep convolutional neural networks actually have non-linear per coordinate transformations, such as ReLU. For example, ReLU applied to a line in 1D space produces a <code>ray</code>, where as in $\mathbf{R}^n$ space, it generally results in a piece-wise linear curve with $n$-joints.</p>
<p>乍一看，这样的实例可以通过简单地减少层的维度来捕获和利用，从而降低操作空间的维度。这已经被MobileNetV1[27]成功利用，通过宽度乘数参数在计算量和精度之间进行有效折衷，并且已经被合并到其他网络的高效模型设计中[20]。遵循这种直觉，宽度乘数方法允许降低激活空间的维度，直到感兴趣的流形横跨整个空间为止。然而，当我们回想到深度卷积神经网络实际上具有非线性的每个坐标变换（例如ReLU）时，这种直觉就会失败。 例如，在1维空间中的一行应用ReLU会产生一个<code>ray</code>，在$\mathbf {R}^n$空间中，它通常会产生一个具有$n$个连接的分段线性曲线。</p>
<p>It is easy to see that in general if a result of a layer transformation ReLU(Bx) has a non-zero volume $S$, the points mapped to interior $S$ are obtained via a linear transformation $B$ of the input, thus indicating that the part of the input space corresponding to the full dimensional output, is limited to a linear transformation. In other words, deep networks only have the power of a linear classifier on the non-zero volume part of the output domain. We refer to supplemental material for a more formal statement.</p>
<p>很容易看出，如果层变换ReLU（Bx）的结果具有非零的体积$S$，映射到内部$S$的点通常通过输入的线性变换$B$获得，因此表明与全维度输出相对应的输入空间的一部分受限于线性变换。换句话说，深层网络只在输出域的非零体积部分具有线性分类器的能力。我们将在补充材料中进行更正式的说明。</p>
<p>On the other hand, when ReLU collapses the channel, it inevitably loses information in that channel. However if we have lots of channels, and there is a a structure in the activation manifold that information might still be preserved in the other channels. In supplemental materials, we show that if the input manifold can be embedded into a significantly lower-dimensional subspace of the activation space then the ReLU transformation preserves the information while introducing the needed complexity into the set of expressible functions.</p>
<p>另一方面，当ReLU破坏通道时，它不可避免地会丢失该通道的信息。但是，如果我们有很多通道，并且激活流形中有一个结构，信息可能仍然保留在其它通道中。在补充材料中，我们说明，如果输入流形可以嵌入到激活空间的显著较低维子空间中，则ReLU变换将保留该信息，同时将所需的复杂性引入到可表达的函数集中。</p>
<p>To summarize, we have highlighted two properties that are indicative of the requirement that the manifold of interest should lie in a low-dimensional subspace of the higher-dimensional activation space:</p>
<ol>
<li><p>If the manifold of interest remains non-zero volume after ReLU transformation, it corresponds to a linear transformation.</p>
</li>
<li><p>ReLU is capable of preserving complete information about the input manifold, but only if the input manifold lies in a low-dimensional subspace of the input space.</p>
</li>
</ol>
<p>总而言之，我们已经强调了两个特性，这些特性表明需要的感兴趣流行应该位于较高维激活空间的低维子空间中：</p>
<p>1.如果感兴趣的流形在ReLU转换后保持非零体积，则其对应于线性转换。</p>
<p>2.只有当输入流形位于输入空间的低维子空间时，ReLU才能保留有关输入流形的完整信息。</p>
<p>These two insights provide us with an empirical hint for optimizing existing neural architectures: assuming the manifold of interest is low-dimensional we can capture this by inserting linear bottleneck layers into the convolutional blocks. Experimental evidence suggests that using linear layers is crucial as it prevents non-linearities from destroying too much information. In Section 6, we show empirically that using non-linear layers in bottlenecks indeed hurts the performance by several percent, further validating our hypothesis. We note that similar reports where non-linearity was helped were reported in [29] where non-linearity was removed from the input of the traditional residual block and that lead to improved performance on CIFAR dataset.</p>
<p>这两个深刻见解为我们提供了优化现有神经架构的经验提示：假设感兴趣流形是低维的，我们可以通过将线性瓶颈层插入到卷积模块中来捕获这一点。实验证据表明，使用线性层是至关重要的，因为它可以防止非线性破坏太多的信息。在第6节中，我们通过经验证明，在瓶颈中使用非线性层确实会使性能降低几个百分点，进一步证实了我们的假设。我们注意到[29]报告了非线性得到帮助的类似报告，其中非线性已从传统残差块的输入中移除，并导致CIFAR数据集的性能得到了改善。</p>
<p>For the remainder of this paper we will be utilizing bottleneck convolutions. We will refer to the ratio between the size of the input bottleneck and the inner size as the expansion ratio.</p>
<p>对于本文的其余部分，我们将利用瓶颈卷积。我们将把输入瓶颈的大小与内部大小之间的比例作为扩展比。</p>
<h3 id="3-3-Inverted-residuals"><a href="#3-3-Inverted-residuals" class="headerlink" title="3.3. Inverted residuals"></a>3.3. Inverted residuals</h3><p>The bottleneck blocks appear similar to residual block where each block contains an input followed by several bottlenecks then followed by expansion [8]. However, inspired by the intuition that the bottlenecks actually contain all the necessary information, while an expansion layer acts merely as an implementation detail that accompanies a non-linear transformation of the tensor, we use shortcuts directly between the bottlenecks. Figure 3 provides a schematic visualization of the difference in the designs. The motivation for inserting shortcuts is similar to that of classical residual connections: we want to improve the ability of a gradient to propagate across multiplier layers. However, the inverted design is considerably more memory efficient (see Section 5 for details), as well as works slightly better in our experiments.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-95ed2cf057e44b0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 3"></p>
<p>Figure 3: The difference between residual block [8, 30] and inverted residual. Diagonally hatched layers do not use non-linearities. We use thickness of each block to indicate its relative number of channels. Note how classical residuals connects the layers with high number of channels, whereas the inverted residuals connect the bottlenecks. Best viewed in color.</p>
<h3 id="3-3-倒置残差"><a href="#3-3-倒置残差" class="headerlink" title="3.3. 倒置残差"></a>3.3. 倒置残差</h3><p>瓶颈块与残差块类似，其中每个块包含一个输入，然后是几个瓶颈，然后是扩展[8]。然而，受直觉的启发，瓶颈实际上包含所有必要的信息，而扩展层只是伴随张量非线性变换的实现细节，我们直接在瓶颈之间使用快捷连接。图3提供了设计差异的示意图。插入快捷连接的动机与经典的残差连接类似：我们想要提高梯度在乘法层之间传播的能力。但是，倒置设计的内存效率要高得多（详见第5节），而且在我们的实验中效果稍好。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-95ed2cf057e44b0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 3"></p>
<p>图3：残差块[8，30]和倒置残差之间的差异。对角阴影线层不使用非线性。我们用每个块的厚度来表明其相对数量的通道。注意经典残差是如何将通道数量较多的层连接起来的，而倒置残差则是连接瓶颈。最好通过颜色看。</p>
<p><strong>Running time and parameter count for bottleneck convolution</strong> The basic implementation structure is illustrated in Table 1. For a block of size $h\times w$, expansion factor $t$ and kernel size $k$ with $d’$ input channels and $d’’$ output channels, the total number of multiply add required is $h \cdot w \cdot d’ \cdot t(d’ + k^2 + d’’)$. Compared with (1) this expression has an extra term, as indeed we have an extra 1 × 1 convolution, however the nature of our networks allows us to utilize much smaller input and output dimensions. In Table 3 we compare the needed sizes for each resolution between MobileNetV1, MobileNetV2 and ShuffleNet.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-d6617f4ac1167d47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 1"></p>
<p>Table 1: Bottleneck residual block transforming from $k$ to $k’$ channels, with stride $s$, and expansion factor $t$.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-04f2dcd1a1cea319.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 3"></p>
<p>Table 3: The max number of channels/memory (in Kb) that needs to be materialized at each spatial resolution for different architectures. We assume 16-bit floats for activations. For ShuffleNet, we use $2x, g = 3$ that matches the performance of MobileNetV1 and MobileNetV2. For the first layer of MobileNetV2 and ShuffleNet we can employ the trick described in Section 5 to reduce memory requirement. Even though ShuffleNet employs bottlenecks elsewhere, the non-bottleneck tensors still need to be materialized due to the presence of shortcuts between non-bottleneck tensors.</p>
<p><strong>瓶颈卷积的运行时间和参数计数</strong>基本实现结构如表1所示。对于大小为$h\times w$的块，扩展因子为$t$，内核大小为$k$，具有$d’$维输入通道和$d’’$维输出通道，所需的乘法加法总数为$h \cdot w \cdot d’ \cdot t(d’ + k^2 + d’’)$。与（1）相比，这个表达式有一个额外项，因为实际上我们有一个额外的1×1卷积，但是我们的网络性质使我们能够利用更小的输入和输出维度。在表3中，我们比较了MobileNetV1，MobileNetV2和ShuffleNet之间每种分辨率所需的尺寸。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-d6617f4ac1167d47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 1"></p>
<p>表1：瓶颈残差块从$k$转换为$k’$个通道，步长为$s$，扩展系数为$t$。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-04f2dcd1a1cea319.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 3"></p>
<p>表3：不同架构中需要在每个空间分辨率上实现的最大通道数/内存（以Kb为单位）。我们假设激活使用16位浮点数。对于ShuffleNet，我们使用与MobileNetV1和MobileNetV2的性能相匹配的$2x，g = 3 $。对于MobileNetV2和ShuffleNet的第一层，我们可以采用第5节中描述的技巧来降低内存需求。尽管ShuffleNet在其它地方使用了瓶颈，但由于存在非瓶颈张量之间的快捷连接，因此非瓶颈张量仍然需要实现。</p>
<h3 id="3-4-Information-flow-interpretation"><a href="#3-4-Information-flow-interpretation" class="headerlink" title="3.4. Information flow interpretation"></a>3.4. Information flow interpretation</h3><p>One interesting property of our architecture is that it provides a natural separation between the input/output domains of the building blocks (bottleneck layers), and the layer transformation – that is a non-linear function that converts input to the output. The former can be seen as the capacity of the network at each layer, whereas the latter as the expressiveness. This is in contrast with traditional convolutional blocks, both regular and separable, where both expressiveness and capacity are tangled together and are functions of the output layer depth.</p>
<h3 id="3-4-信息流解释"><a href="#3-4-信息流解释" class="headerlink" title="3.4. 信息流解释"></a>3.4. 信息流解释</h3><p>我们架构的一个有趣特性是它在构建块（瓶颈层）的输入/输出域与层转换之间提供了自然分离——这是一种将输入转换为输出的非线性函数。前者可以看作是网络在每一层的容量，而后者则是表现力。与常规和可分离的传统卷积块相比，其中表现力和容量都缠结在一起并且是输出层深度的函数。</p>
<p>In particular, in our case, when inner layer depth is 0 the underlying convolution is the identity function thanks to the shortcut connection. When the expansion ratio is smaller than 1, this is a classical residual convolutional block [8, 30]. However, for our purposes we show that expansion ratio greater than 1 is the most useful.</p>
<p>特别是在我们的实例中，当内层深度为0时，由于快捷连接，基础卷积是恒等函数。当扩展比率小于1时，这是一个经典的残差卷积块[8，30]。但是，就我们的目的而言，我们表明扩大比率大于1是最有用的。</p>
<p>This interpretation allows us to study the expressiveness of the network separately from its capacity and we believe that further exploration of this separation is warranted to provide a better understanding of the network properties.</p>
<p>这种解释使我们能够独立于其容量研究网络的表现力，并且我们认为需要进一步探索这种分离，以便更好地理解网络性质。</p>
<h2 id="4-Model-Architecture"><a href="#4-Model-Architecture" class="headerlink" title="4. Model Architecture"></a>4. Model Architecture</h2><p>Now we describe our architecture in detail. As discussed in the previous section the basic building block is a bottleneck depth-separable convolution with residuals. The detailed structure of this block is shown in Table 1. The architecture of MobileNetV2 contains the initial fully convolution layer with 32 filters, followed by 19 residual bottleneck layers described in the Table 2. We use ReLU6 as the non-linearity because of its robustness when used with low-precision computation [27]. We always use kernel size 3 × 3 as is standard for modern networks, and utilize dropout and batch normalization during training.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-7c24424dcf9e2997.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 2"></p>
<p>Table 2: MobileNetV2 : Each line describes a sequence of 1 or more identical (modulo stride) layers, repeated $n$ times. All layers in the same sequence have the same number $c$ of output channels. The first layer of each sequence has a stride $s$ and all others use stride $1$. All spatial convolutions use 3 × 3 kernels. The expansion factor $t$ is always applied to the input size as described in Table 1.</p>
<h2 id="4-模型架构"><a href="#4-模型架构" class="headerlink" title="4. 模型架构"></a>4. 模型架构</h2><p>现在我们详细描述我们的架构。正如前一节所讨论的那样，基本构件块是一个瓶颈深度可分离的残差卷积。该模块的详细结构如表1所示。MobileNetV2的架构包含具有32个滤波器的初始全卷积层，接着是表2中描述的19个残差瓶颈层。我们使用ReLU6作为非线性，因为用于低精度计算时它的鲁棒性[27]。我们总是使用现代网络中的标准核尺寸3×3，并在训练期间利用丢弃和批归一化。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-7c24424dcf9e2997.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 2"></p>
<p>表2：MobileNetV2：每行描述一个或多个相同（模步长）层的序列，重复$n$次。同一序列中的所有图层具有相同数量的$c$个输出通道。每个序列的第一层有一个步长$s$，所有其他的都使用长$1$。所有空间卷积使用3×3的核。扩展系数$t$总是应用于输入尺寸，如表1所述。</p>
<p>With the exception of the first layer, we use constant expansion rate throughout the network. In our experiments we find that expansion rates between 5 and 10 result in nearly identical performance curves, with smaller networks being better off with slightly smaller expansion rates and larger networks having slightly better performance with larger expansion rates.</p>
<p>除第一层外，我们在整个网络中使用恒定的扩展率。在我们的实验中，我们发现5到10之间的扩展速率导致几乎相同的性能曲线，较小的网络以较小的扩展速率更好，而较大的网络在较大扩展速率时具有稍微更好的性能。</p>
<p>For all our main experiments we use expansion factor of $6$ applied to the size of the input tensor. For example, for a bottleneck layer that takes $64$-channel input tensor and produces a tensor with $128$ channels, the intermediate expansion layer is then $64 · 6 = 384$ channels.</p>
<p>对于我们所有的主要实验，我们使用扩展因子$6$来应用于输入张量的大小。例如，对于瓶颈层采用$64$通道的输入张量并产生具有$128$通道的张量，中间扩展层则具有$64·6 =384$个通道。</p>
<p>As in [27] we tailor our architecture to different performance points, by using the input image resolution and width multiplier as tunable hyperparameters, that can be adjusted depending on desired accuracy/performance trade-offs. Our primary network (width multiplier 1, 224 × 224), has a computational cost of 300 million multiply-adds and uses 3.4 million parameters. We explore the performance trade offs, for input resolutions from 96 to 224, and width multipliers of 0.35 to 1.4. The network computational cost ranges from 7 multiply adds to 585M MAdds, while the model size vary between 1.7M and 6.9M parameters.</p>
<p>和[27]一样，我们通过使用输入图像分辨率和宽度倍数作为可调超参数来调整我们的架构以适应不同的性能点，可以根据所需的精度/性能权衡来调整。我们的主要网络（宽度乘数1，224×224）的计算成本为3亿次乘法，并使用了340万个参数。我们研究了性能权衡，输入分辨率从96到224，宽度乘数从0.35到1.4。网络计算成本范围从7次乘法增加到585M MAdds，而模型大小在1.7M个参数和6.9M个参数之间变化。</p>
<p>One minor implementation difference, with [27] is that for multipliers less than one, we apply width multiplier to all layers except the very last convolutional layer. This improves performance for smaller models.</p>
<p>一个较小的实现差异，[27]是对于小于1的乘数，我们将宽度乘数应用于除最后一个卷积层以外的所有层。这可以提高更小模型的性能。</p>
<h2 id="5-Implementation-Notes"><a href="#5-Implementation-Notes" class="headerlink" title="5. Implementation Notes"></a>5. Implementation Notes</h2><h3 id="5-1-Memory-efficient-inference"><a href="#5-1-Memory-efficient-inference" class="headerlink" title="5.1. Memory efficient inference"></a>5.1. Memory efficient inference</h3><p>The inverted residual bottleneck layers allow a particularly memory efficient implementation which is very important for mobile applications. A standard efficient implementation of inference that uses for instance TensorFlow[31] or Caffe [32], builds a directed acyclic compute hypergraph $G$, consisting of edges representing the operations and nodes representing tensors of intermediate computation. The computation is scheduled in order to minimize the total number of tensors that needs to be stored in memory. In the most general case, it searches over all plausible computation orders $\Sigma (G)$ and picks the one that minimizes $$ M(G) = \min_{\pi\in \Sigma(G)} \max_{i \in 1..n} \left[\sum_{A \in R(i, \pi, G)} |A|\right] + \text{size}(\pi_i). $$ where $R(i, \pi, G)$ is the list of intermediate tensors that are connected to any of $\pi_{i}\dots \pi_{n}$ nodes, $|A|$ represents the size of the tensor $A$ and $size(i)$ is the total amount of memory needed for internal storage during operation $i$.</p>
<h2 id="5-实现说明"><a href="#5-实现说明" class="headerlink" title="5. 实现说明"></a>5. 实现说明</h2><h3 id="5-1-内存有效推断"><a href="#5-1-内存有效推断" class="headerlink" title="5.1. 内存有效推断"></a>5.1. 内存有效推断</h3><p>倒置的残差颈层允许特定地内存有效的实现，这对于移动应用非常重要。使用TensorFlow[31]或Caffe[32]等标准高效的推断实现，构建了一个有向无环计算超图$G$，由表示操作的边和代表中间计算张量的节点组成。预定计算是为了最小化需要存储在内存中的张量总数。在最一般的情况下，它会搜索所有合理的计算顺序$\Sigma (G)$，并选择最小化$$ M(G) = \min_{\pi\in \Sigma(G)} \max_{i \in 1..n} \left[\sum_{A \in R(i, \pi, G)} |A|\right] + \text{size}(\pi_i)$$。$$其中$R(i, \pi, G)$是连接到任何$\pi_{i}\dots \pi_{n}$节点的中间张量列表，$|A|$表示张量$A$的大小，$size(i)$是操作$i$期间内部存储所需的总内存量。</p>
<p>For graphs that have only trivial parallel structure (such as residual connection), there is only one non-trivial feasible computation order, and thus the total amount and a bound on the memory needed for inference on compute graph $G$ can be simplified: $$M(G) = \max_{op \in G} \left[\sum_{A \in \text{op}_{inp}} |A| + \sum_{B \in \text{op}_{out}} |B| + |op|\right] \tag {2}$$ Or to restate, the amount of memory is simply the maximum total size of combined inputs and outputs across all operations. In what follows we show that if we treat a bottleneck residual block as a single operation (and treat inner convolution as a disposable tensor), the total amount of memory would be dominated by the size of bottleneck tensors, rather than the size of tensors that are internal to bottleneck (and much larger).</p>
<p>对于仅具有平凡并行结构（例如残差连接）的图，只有一个非平凡的可行计算顺序，因此可以简化计算图$G$推断所需的内存总量和界限：$$M(G) = \max_{op \in G} \left[\sum_{A \in \text{op}_{inp}} |A| + \sum_{B \in \text{op}_{out}} |B| + |op|\right] \tag {2}$$或者重申，内存量只是在所有操作中组合输入和输出的最大总大小。在下文中我们将展示如果我们将瓶颈残差块视为单一操作（并将内部卷积视为一次性张量），则总内存量将由瓶颈张量的大小决定，而不是瓶颈的内部张量的大小（更大）。</p>
<p><strong>Bottleneck Residual Block</strong> $\mathcal{F}(x)$ shown in Figure 3b can be expressed as a composition of three operators $\mathcal{F}(x) = [A \circ \mathcal{N} \circ  B] x$, where $A$ is a linear transformation $A:\mathcal{R}^{s \times s \times k} \rightarrow \mathcal{R}^{s \times s \times n}$,  $\mathcal{N}$ is a non-linear per-channel transformation: $\mathcal{N}: \mathcal{R}^{s \times s \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times n}$, and $B$ is again a linear transformation to the output domain: $B: \mathcal{R}^{s’ \times s’ \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times k’}$.</p>
<p><strong>瓶颈残差块</strong> 图3b中所示的$\mathcal{F}(x)$可以表示为三个运算符的组合$\mathcal{F}(x) = [A \circ \mathcal{N} \circ  B] x$，其中$A$是线性变换$A:\mathcal{R}^{s \times s \times k} \rightarrow \mathcal{R}^{s \times s \times n}$，$\mathcal{N}$是一个非线性的每个通道的转换：$\mathcal{N}: \mathcal{R}^{s \times s \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times n}$，$B$是输出域的线性转换：$B: \mathcal{R}^{s’ \times s’ \times n} \rightarrow \mathcal{R}^{s’ \times s’ \times k’}$。</p>
<p>For our networks $\mathcal{N} = ReLU6 \circ dwise \circ ReLU6$, but the results apply to any per-channel transformation. Suppose the size of the input domain is $|x|$ and the size of the output domain is $|y|$, then the memory required to compute $F(X)$ can be as low as $|s^2 k| + |s’^2 k’| + O(\max(s^2, s’^2))$.</p>
<p>对于我们的网络$\mathcal{N} = ReLU6 \circ dwise \circ ReLU6$，但结果适用于任何的按通道转换。假设输入域的大小是$|x|$并且输出域的大小是$|y|$，那么计算$F(X)$所需的内存可以低至$|s^2 k| + |s’^2 k’| + O(\max(s^2, s’^2))$。</p>
<p>The algorithm is based on the fact that the inner tensor $\cal I$ can be represented as concatenation of $t$ tensors, of size $n/t$ each and our function can then be represented as $$\mathcal{F}(x) = \sum_{i=1}^t (A_i \circ N \circ B_i)(x)$$ by  accumulating the sum, we only require one intermediate block of size $n/t$ to be kept in memory at all times. Using $n=t$ we end up having to keep only a single channel of the intermediate representation at all times. The two constraints that enabled us to use this trick is (a) the fact that the inner transformation (which includes non-linearity and depthwise) is per-channel, and (b) the consecutive non-per-channel operators have significant ratio of the input size to the output. For most of the traditional neural networks, such trick would not produce a significant improvement. </p>
<p>该算法基于以下事实：内部张量$\cal I$可以表示为$t$张量的连接，每个大小为$n/t$，则我们的函数可以表示为$$\mathcal{F}(x) = \sum_{i=1}^t (A_i \circ N \circ B_i)(x)$$通过累加和，我们只需要将一个大小为$n/t$的中间块始终保留在内存中。使用$n=t$，我们最终只需要保留中间表示的单个通道。使我们能够使用这一技巧的两个约束是（a）内部变换（包括非线性和深度）是每个通道的事实，以及（b）连续的非按通道运算符具有显著的输入输出大小比。对于大多数传统的神经网络，这种技巧不会产生显著的改善。</p>
<p>We note that, the  number of multiply-adds operators needed to compute $F(X)$ using $t$-way split is independent of $t$, however in existing implementations we find that replacing one matrix multiplication with several smaller ones hurts runtime performance due to increased cache misses. We find that this approach is the most helpful to be used with $t$ being a small constant between $2$ and $5$. It significantly reduces the memory requirement, but still allows one to utilize most of the efficiencies gained by using highly optimized matrix multiplication and convolution operators provided by deep learning frameworks. It remains to be seen if special framework level optimization may lead to further runtime improvements. </p>
<p>我们注意到，使用$t$路分割计算$F(X)$所需的乘加运算符的数目是独立于$t$的，但在现有实现中，我们发现由于增加的缓存未命中，用几个较小的矩阵乘法替换一个矩阵乘法会很损坏运行时的性能 。我们发现这种方法最有用，$t$是$2$和$5$之间的一个小常数。它显著降低了内存需求，但仍然可以利用深度学习框架提供的高度优化的矩阵乘法和卷积算子来获得的大部分效率。如果特殊的框架级优化可能导致进一步的运行时改进，这个方法还有待观察。</p>
<h2 id="6-Experiments"><a href="#6-Experiments" class="headerlink" title="6. Experiments"></a>6. Experiments</h2><h3 id="6-1-ImageNet-Classification"><a href="#6-1-ImageNet-Classification" class="headerlink" title="6.1. ImageNet Classification"></a>6.1. ImageNet Classification</h3><p><strong>Training setup</strong> We train our models using TensorFlow[31]. We use the standard RMSPropOptimizer with both decay and momentum set to 0.9. We use batch normalization after every layer, and the standard weight decay is set to 0.00004. Following MobileNetV1[27] setup we use initial learning rate of 0.045, and learning rate decay rate of 0.98 per epoch. We use 16 GPU asynchronous workers, and a batch size of 96.</p>
<h2 id="6-实验"><a href="#6-实验" class="headerlink" title="6. 实验"></a>6. 实验</h2><h3 id="6-1-ImageNet分类"><a href="#6-1-ImageNet分类" class="headerlink" title="6.1. ImageNet分类"></a>6.1. ImageNet分类</h3><p><strong>训练设置</strong>我们使用TensorFlow[31]训练我们的模型。我们使用标准的RMSPropOptimizer，将衰减和动量都设置为0.9。我们在每层之后使用批标准化，并将标准权重衰减设置为0.00004。遵循MobileNetV1 [27]的设置，我们使用初始学习率为0.045，学习率的衰减比率为每个迭代周期衰减0.98。我们使用16个GPU异步，批大小为96。</p>
<p><strong>Results</strong> We compare our networks against MobileNetV1, ShuffleNet and NASNet-A models. The statistics of a few selected models is shown in Table 4 with the full performance graph shown in Figure 5.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-411f1873403d0fca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 4"></p>
<p>Table 4: Performance on ImageNet, comparison for different networks. As is common practice for ops, we count the total number of Multiply-Adds. In the last column we report running time in milliseconds (ms) for a single large core of the Google Pixel 1 phone (using TF-Lite). We do not report ShuffleNet numbers as efficient group convolutions and shuffling are not yet supported.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-e54b02e9564b2f01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 5"></p>
<p>Figure 5: Performance curve of MobileNetV2 vs MobileNetV1, ShuffleNet, NAS. For our networks we use multipliers 0.35, 0.5, 0.75, 1.0 for all resolutions, and additional 1.4 for for 224. Best viewed in color.</p>
<p><strong>结果</strong>我们将我们的网络与MobileNetV1，ShuffleNet和NASNet-A模型进行了比较。表4列出了一些选定模型的统计数据，完整的性能图如图5所示。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-411f1873403d0fca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 4"></p>
<p>表4：比较不同网络在ImageNet上的性能。正如ops的常见做法一样，我们计算Multiply-Adds的总数。在最后一列中，我们报告了Google Pixel 1手机上的一个大型核心（使用TF-Lite）的运行时间，以毫秒（ms）为单位。我们不报告ShuffleNet的数字，因为高效的群组卷积和混排尚未支持。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-e54b02e9564b2f01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 5"></p>
<p>图5：MobileNetV2与MobileNetV1，ShuffleNet，NAS的性能曲线。对于我们的网络，我们对所有分辨率使用乘数0.35，0.5，0.75，1.0，对于分辨率为224，我们使用乘数1.4。</p>
<h3 id="6-2-Object-Detection"><a href="#6-2-Object-Detection" class="headerlink" title="6.2. Object Detection"></a>6.2. Object Detection</h3><p>We evaluate and compare the performance of MobileNetV2 and MobileNetV1 as feature extractors [33] for object detection with a modified version of the Single Shot Detector (SSD) [34] on COCO dataset [2]. We also compare to YOLOv2 [35] and original SSD (with VGG-16 [6] as base network) as baselines. We do not compare performance with other architectures such as Faster-RCNN [36] and RFCN [37] since our focus is on mobile/real-time models.</p>
<h3 id="6-2-目标检测"><a href="#6-2-目标检测" class="headerlink" title="6.2. 目标检测"></a>6.2. 目标检测</h3><p>我们评估和比较了MobileNetV2和MobileNetV1的性能，MobileNetV1使用COCO数据集[2]上Single Shot Detector（SSD）[34]的修改版本作为目标检测的特征提取器[33]。我们还将YOLOv2[35]和原始SSD（以VGG-16[6]为基础网络）作为基准进行比较。由于我们专注于移动/实时模型，因此我们不会比较Faster-RCNN[36]和RFCN[37]等其它架构的性能。</p>
<p><strong>SSDLite:</strong> In this paper, we introduce a mobile friendly variant of regular SSD. We replace all the regular convolutions with separable convolutions (depthwise followed by $1 \times 1$ projection) in SSD prediction layers. This design is in line with the overall design of MobileNets and is seen to be much more computationally efficient. We call this modified version SSDLite. Compared to regular SSD, SSDLite dramatically reduces both parameter count and computational cost as shown in Table 5.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-85996725f1f95a1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 5"></p>
<p>Table 5: Comparison of the size and the computational cost between SSD and SSDLite configured with MobileNetV2 and making predictions for 80 classes.</p>
<p><strong>SSDLite</strong> 在本文中，我们将介绍常规SSD的移动友好型变种。我们在SSD预测层中用可分离卷积（深度方向后接$1\times 1$投影）替换所有常规卷积。这种设计符合MobileNets的整体设计，并且在计算上效率更高。我们称之为修改版本的SSDLite。与常规SSD相比，SSDLite显著降低了参数计数和计算成本，如表5所示。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-85996725f1f95a1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 5"></p>
<p>表5：使用MobileNetV2配置的SSD和SSDLite之间的大小和计算成本以及对80个类进行预测的比较。</p>
<p>For MobileNetV1, we follow the setup in [33]. For MobileNetV2, the first layer of SSDLite is attached to the expansion of layer 15 (with output stride of 16). The second and the rest of SSDLite layers are attached on top of the last layer (with output stride of 32). This setup is consistent with MobileNetV1 as all layers are attached to the feature map of the same output strides.</p>
<p>对于MobileNetV1，我们按照[33]中的设置进行。对于MobileNetV2，SSDLite的第一层被附加到层15的扩展（输出步长为16）。SSDLite层的第二层和其余层连接在最后一层的顶部（输出步长为32）。此设置与MobileNetV1一致，因为所有层都附加到相同输出步长的特征图上。</p>
<p>Both MobileNet models are trained and evaluated with Open Source TensorFlow Object Detection API [38]. The input resolution of both models is $320 \times 320$. We benchmark and compare both mAP (COCO challenge metrics), number of parameters and number of Multiply-Adds. The results are shown in Table 6. MobileNetV2 SSDLite is not only the most efficient model, but also the most accurate of the three. Notably, MobileNetV2 SSDLite is $20\times$ more efficient and $10\times$ smaller while still outperforms YOLOv2 on COCO dataset.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-f9daccb9ae7d1cc9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 6"></p>
<p>Table 6: Performance comparison of MobileNetV2 + SSDLite and other realtime detectors on the COCO dataset object detection task. MobileNetV2 + SSDLite achieves competitive accuracy with significantly fewer parameters and smaller computational complexity. All models are trained on <code>trainval35k</code> and evaluated on <code>test-dev</code>. SSD/YOLOv2 numbers are from [35]. The running time is reported for the large core of the Google Pixel 1 phone, using an internal version of the TF-Lite engine.</p>
<p>MobileNet模型都经过了开源TensorFlow目标检测API的训练和评估[38]。 两个模型的输入分辨率为$320 \times 320$。我们进行了基准测试并比较了mAP（COCO挑战度量标准），参数数量和Multiply-Adds数量。结果如表6所示。MobileNetV2 SSDLite不仅是最高效的模型，而且也是三者中最准确的模型。值得注意的是，MobileNetV2 SSDLite效率高20倍，模型要小10倍，但仍优于COCO数据集上的YOLOv2。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-f9daccb9ae7d1cc9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 6"></p>
<p>表6：MobileNetV2+SSDLite和其他实时检测器在COCO数据集目标检测任务中的性能比较。MobileNetV2+SSDLite以更少的参数和更小的计算复杂性实现了具有竞争力的精度。所有模型都在<code>trainval35k</code>上进行训练，并在<code>test-dev</code>上进行评估。SSD/YOLOv2的数字来自于[35]。使用内部版本的TF-Lite引擎，报告了在Google Pixel 1手机的大型核心上的运行时间。</p>
<h3 id="6-3-Semantic-Segmentation"><a href="#6-3-Semantic-Segmentation" class="headerlink" title="6.3. Semantic Segmentation"></a>6.3. Semantic Segmentation</h3><p>In this section, we compare MobileNetV1 and MobileNetV2 models used as feature extractors with DeepLabv3 [39] for the task of mobile semantic segmentation. DeepLabv3 adopts atrous convolution [40, 41, 42], a powerful tool to explicitly control the resolution of computed feature maps, and builds five parallel heads including (a) Atrous Spatial Pyramid Pooling module (ASPP) [43] containing three $3 \times 3$ convolutions with different atrous rates, (b) $1\times 1$ convolution head, and (c) Image-level features [44]. We denote by output stride the ratio of input image spatial resolution to final output resolution, which is controlled by applying the atrous convolution properly. For semantic segmentation, we usually employ output $stride = 16$ or $8$ for denser feature maps. We conduct the experiments on the PASCAL VOC 2012 dataset [3], with extra annotated images from [45] and evaluation metric mIOU.</p>
<h3 id="6-3-语义分割"><a href="#6-3-语义分割" class="headerlink" title="6.3. 语义分割"></a>6.3. 语义分割</h3><p>在本节中，我们使用MobileNetV1和MobileNetV2模型作为特征提取器与DeepLabv3[39]在移动语义分割任务上进行比较。DeepLabv3采用了空洞卷积[40,41,42]，这是一种显式控制计算特征映射分辨率的强大工具，并构建了五个平行头部，包括（a）包含三个具有不同空洞率的$3 \times 3$卷积的Atrous Spatial Pyramid Pooling模块(ASPP)[43]，（b）$1 \times 1$卷积头部，以及（c）图像级特征[44]。我们用输出步长来表示输入图像空间分辨率与最终输出分辨率的比值，该分辨率通过适当地应用空洞卷积来控制。对于语义分割，我们通常使用输出$stride = 16$或$8$来获取更密集的特征映射。我们在PASCAL VOC 2012数据集[3]上进行了实验，使用[45]中的额外标注图像和评估指标mIOU。</p>
<p>To build a mobile model, we experimented with three design variations: (1) different feature extractors, (2) simplifying the DeepLabv3 heads for faster computation, and (3) different inference strategies for boosting the performance. Our results are summarized in Table 7. We have observed that: (a) the inference strategies, including multi-scale inputs and adding left-right flipped images, significantly increase the MAdds and thus are not suitable for on-device applications, (b) using output stride = 16 is more efficient than output stride = 8, (c) MobileNetV1 is already a powerful feature extractor and only requires about 4.9 - 5.7 times fewer MAdds than ResNet-101 [8] (e.g., mIOU: 78.56 vs 82.70, and MAdds: 941.9B vs 4870.6B), (d) it is more efficient to build DeepLabv3 heads on top of the second last feature map of MobileNetV2 than on the original last-layer feature map, since the second to last feature map contains 320 channels instead of 1280, and by doing so, we attain similar performance, but require about 2.5 times fewer operations than the MobileNetV1 counterparts, and (e) DeepLabv3 heads are computationally expensive and removing the ASPP module significantly reduces the MAdds with only a slight performance degradation. In the end of the Table 7, we identify a potential candidate for on-device applications (in bold face), which attains $75.32\%$ mIOU and only requires 2.75B MAdds.</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-a62e21b1f981dbb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 7"></p>
<p>Table 7: MobileNet + DeepLabv3 inference strategy on the PASCAL VOC 2012 validation set. MNet V2*: Second last feature map is used for DeepLabv3 heads, which includes (1) Atrous Spatial Pyramid Pooling (ASPP) module, and (2) $1 \times 1$ convolution as well as image-pooling feature. OS: output stride that controls the output resolution of the segmentation map. MF: Multi-scale and left-right flipped inputs during test. All of the models have been pretrained on COCO. The potential candidate for on-device applications is shown in bold face. PASCAL images have dimension $512 \times 512$ and atrous convolution allows us to control output feature resolution without increasing the number of parameters.</p>
<p>为了构建移动模型，我们尝试了三种设计变体：（1）不同的特征提取器，（2）简化DeepLabv3头部以加快计算速度，以及（3）提高性能的不同推断策略。我们的结果总结在表7中。我们已经观察到：（a）包括多尺度输入和添加左右翻转图像的推断策略显著增加了MAdds，因此不适合于在设备上应用，（b）使用输出步长16比使用输出步长8更有效率，（c）MobileNetV1已经是一个强大的特征提取器，并且只需要比ResNet-101少约4.9-5.7倍的MAdd[8]（例如，mIOU：78.56与82.70和MAdds：941.9B vs 4870.6B），（d）在MobileNetV2的倒数第二个特征映射的顶部构建DeepLabv3头部比在原始的最后一个特征映射上更高效，因为倒数第二个特征映射包含320个通道而不是1280个通道，这样我们就可以达到类似的性能，但是要比MobileNetV1的通道少2.5倍，（e）DeepLabv3头部的计算成本很高，移除ASPP模块会显著减少MAdd并且只会稍微降低性能。在表7末尾，我们鉴定了一个设备上的潜在候选应用（粗体），该应用可以达到$75.32\%$mIOU并且只需要2.75B MAdds。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-a62e21b1f981dbb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Table 7"></p>
<p>表7：PASCAL VOC 2012验证集上的MobileNet+DeepLabv3推断策略。MNet V2*：用于DeepLabv3头部的倒数第二个特征映射，其中包括（1）Atrous Spatial Pyramid Pooling（ASPP）模块和（2）$1\times 1$卷积以及图像池化功能。OS：控制分割映射输出分辨率的输出步长。MF：测试期间多尺度和左右翻转输入。所有的模型都在COCO上进行预训练。设备上的潜在候选应用以粗体显示。PASCAL图像的尺寸为$ 512 \ times 512 $，而空洞卷积使得我们可以在不增加参数数量的情况下控制输出特征分辨率。</p>
<h3 id="6-4-Ablation-study"><a href="#6-4-Ablation-study" class="headerlink" title="6.4. Ablation study"></a>6.4. Ablation study</h3><p><strong>Inverted residual connections</strong>. The importance of residual connection has been studied extensively [8, 30, 46]. The new result reported in this paper is that the shortcut connecting bottleneck perform better than shortcuts connecting the expanded layers (see Figure 6b for comparison).</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-51a75c72154fa734.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 6"></p>
<p>Figure 6: The impact of non-linearities and various types of shortcut (residual) connections.</p>
<h3 id="6-4-消融研究"><a href="#6-4-消融研究" class="headerlink" title="6.4. 消融研究"></a>6.4. 消融研究</h3><p><strong>倒置残差连接</strong>。残差连接的重要性已被广泛研究[8，30，46]。本文报告的新结果是连接瓶颈的快捷连接性能优于连接扩展层的的快捷连接（请参见图6b以供比较）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3232548-51a75c72154fa734.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 6"></p>
<p>图6：非线性和各种快捷（残差）连接的影响。</p>
<p><strong>Importance of linear bottlenecks</strong>. The linear bottleneck models are strictly less powerful than models with non-linearities, because the activations can always operate in linear regime with appropriate changes to biases and scaling. However our experiments shown in Figure 6a indicate that linear bottlenecks improve performance, providing support that non-linearity destroys information in low-dimensional space.</p>
<p><strong>线性瓶颈</strong>的重要性。线性瓶颈模型的严格来说比非线性模型要弱一些，因为激活总是可以在线性状态下进行，并对偏差和缩放进行适当的修改。然而，我们在图6a中展示的实验表明，线性瓶颈改善了性能，为非线性破坏低维空间中的信息提供了支持。</p>
<h2 id="7-Conclusions-and-future-work"><a href="#7-Conclusions-and-future-work" class="headerlink" title="7. Conclusions and future work"></a>7. Conclusions and future work</h2><p>We described a very simple network architecture that allowed us to build a family of highly efficient mobile models. Our basic building unit, has several properties that make it particularly suitable for mobile applications. It allows very memory-efficient inference and relies utilize standard operations present in all neural frameworks.</p>
<h2 id="7-总结及将来工作"><a href="#7-总结及将来工作" class="headerlink" title="7. 总结及将来工作"></a>7. 总结及将来工作</h2><p>我们描述了一个非常简单的网络架构，使我们能够构建一系列高效的移动模型。我们的基本构建单元具有多种特性，使其特别适用于移动应用。它允许非常有效的内存推断，并依赖利用所有神经框架中的标准操作。</p>
<p>For the ImageNet dataset, our architecture improves the state of the art for wide range of performance points. For object detection task, our network outperforms state-of-art realtime detectors on COCO dataset both in terms of accuracy and model complexity. Notably, our architecture combined with the SSDLite detection module is 20× less computation and 10× less parameters than YOLOv2.</p>
<p>对于ImageNet数据集，我们的架构改善了许多性能点的最新技术水平。对于目标检测任务，我们的网络在精度和模型复杂度方面都优于COCO数据集上的最新实时检测器。值得注意的是，我们的架构与SSDLite检测模块相比，计算量少20倍，参数比YOLOv2少10倍。</p>
<p>On the theoretical side: the proposed convolutional block has a unique property that allows to separate the network expressiviness (encoded by expansion layers) from its capacity (encoded by bottleneck inputs). Exploring this is an important direction for future research.</p>
<p>理论上：所提出的卷积块具有独特的属性，允许将网络表现力（由扩展层编码）与其容量（由瓶颈输入编码）分开。探索这个是未来研究的重要方向。</p>
<h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>We would like to thank Matt Streeter and Sergey Ioffe for their helpful feedback and discussion.</p>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>我们要感谢Matt Streeter和Sergey Ioffe的有益反馈和讨论。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. Int. J. Comput. Vision, 115(3):211–252, December 2015.</p>
<p>[2] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV, 2014.</p>
<p>[3] Mark Everingham, S. M. Ali Eslami, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserma. The pascal visual object classes challenge a retrospective. IJCV, 2014.</p>
<p>[4] Mobilenetv2 source code. Available from <a href="https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet" target="_blank" rel="external">https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet</a>.</p>
<p>[5] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Bartlett et al. [48], pages 1106–1114.</p>
<p>[6] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.</p>
<p>[7] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015, pages 1–9. IEEE Computer Society, 2015.</p>
<p>[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.</p>
<p>[9] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13:281–305, 2012.</p>
<p>[10] Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian optimization of machine learning algorithms. In Bartlett et al. [48], pages 2960–2968.</p>
<p>[11] Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md. Mostofa Ali Patwary, Prabhat, and Ryan P. Adams. Scalable bayesian optimization using deep neural networks. In Francis R. Bach and David M. Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR Workshop and Conference Proceedings, pages 2171–2180. JMLR.org, 2015.</p>
<p>[12] Babak Hassibi and David G. Stork. Second order derivatives for network pruning: Optimal brain surgeon. In Stephen Jose Hanson, Jack D. Cowan, and C. Lee Giles, editors, Advances in Neural Information Processing Systems 5, [NIPS Conference, Denver, Colorado, USA, November 30 - December 3, 1992], pages 164–171. Morgan Kaufmann, 1992.</p>
<p>[13] Yann LeCun, John S. Denker, and Sara A. Solla. Optimal brain damage. In David S. Touretzky, editor, Advances in Neural Information Processing Systems 2, [NIPS Conference, Denver, Colorado, USA, November 27-30, 1989], pages 598–605. Morgan Kaufmann, 1989.</p>
<p>[14] Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights and connections for efficient neural network. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 1135–1143, 2015.</p>
<p>[15] Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Shijian Tang, Erich Elsen, Bryan Catanzaro, John Tran, and William J. Dally. DSD: regularizing deep neural networks with dense-sparse-dense training flow. CoRR, abs/1607.04381, 2016.</p>
<p>[16] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 1379–1387, 2016.</p>
<p>[17] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. CoRR, abs/1608.08710, 2016.</p>
<p>[18] Karim Ahmed and Lorenzo Torresani. Connectivity learning in multi-branch networks. CoRR, abs/1709.09582, 2017.</p>
<p>[19] Tom Veniat and Ludovic Denoyer. Learning time-efficient deep architectures with budgeted super networks. CoRR, abs/1706.00046, 2017.</p>
<p>[20] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CoRR, abs/1707.01083, 2017.</p>
<p>[21] Soravit Changpinyo, Mark Sandler, and Andrey Zhmoginov. The power of sparsity in convolutional neural networks. CoRR, abs/1702.06257, 2017.</p>
<p>[22] Min Wang, Baoyuan Liu, and Hassan Foroosh. Design of efficient convolutional layers using single intra-channel convolution, topological subdivisioning and spatial ”bottleneck” structure. CoRR, abs/1608.04337, 2016.</p>
<p>[23] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. Learning transferable architectures for scalable image recognition. CoRR, abs/1707.07012, 2017.</p>
<p>[24] Lingxi Xie and Alan L. Yuille. Genetic CNN. CoRR, abs/1703.01513, 2017.</p>
<p>[25] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V. Le, and Alexey Kurakin. Large-scale evolution of image classifiers. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 2902–2911. PMLR, 2017.</p>
<p>[26] Barret Zoph and Quoc V. Le. Neural architecture search with reinforcement learning. CoRR, abs/1611.01578, 2016.</p>
<p>[27] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam.<br>Mobilenets: Efficient convolutional neural networks for mobile vision applications. CoRR, abs/1704.04861, 2017.</p>
<p>[28] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.</p>
<p>[29] Dongyoon Han, Jiwhan Kim, and Junmo Kim. Deep pyramidal residual networks. CoRR, abs/1610.02915, 2016.</p>
<p>[30] Saining Xie, Ross B. Girshick, Piotr Dolla ́r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. CoRR, abs/1611.05431, 2016.</p>
<p>[31] Martın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.</p>
<p>[32] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embed- ding. arXiv preprint arXiv:1408.5093, 2014.</p>
<p>[33] Jonathan Huang, Vivek Rathod, Chen Sun, Men- glong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, et al. Speed/accuracy trade-offs for modern convolutional object detectors. In CVPR, 2017.</p>
<p>[34] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In ECCV, 2016.</p>
<p>[35] Joseph Redmon and Ali Farhadi. Yolo9000: Better, faster, stronger. arXiv preprint arXiv:1612.08242, 2016.</p>
<p>[36] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015.</p>
<p>[37] Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. R-fcn: Object detection via region-based fully convolutional networks. In Advances in neural information processing systems, pages 379–387, 2016.</p>
<p>[38] Jonathan Huang, Vivek Rathod, Derek Chow, Chen Sun, and Menglong Zhu. Tensorflow object detection api, 2017.</p>
<p>[39] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. CoRR, abs/1706.05587, 2017.</p>
<p>[40] Matthias Holschneider, Richard Kronland-Martinet, Jean Morlet, and Ph Tchamitchian. A real-time algorithm for signal analysis with the help of the wavelet transform. In Wavelets: Time-Frequency Methods and Phase Space, pages 289–297. 1989.</p>
<p>[41] Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu, Rob Fergus, and Yann LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. arXiv:1312.6229, 2013.</p>
<p>[42] George Papandreou,Iasonas Kokkinos, and Pierre Andre Savalle. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection. In CVPR, 2015.</p>
<p>[43] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. TPAMI, 2017.</p>
<p>[44] Wei Liu, Andrew Rabinovich, and Alexander C. Berg. Parsenet: Looking wider to see better. CoRR, abs/1506.04579, 2015.</p>
<p>[45] Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In ICCV, 2011.</p>
<p>[46] Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016.</p>
<p>[47] Guido Montúfar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS’14, pages 2924–2932, Cambridge, MA, USA, 2014. MIT Press.</p>
<p>[48] Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, Léon Bottou, and Kilian Q. Weinberger, editors. Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States, 2012.</p>
]]></content>
    
    <summary type="html">
    
      MobileNetV2——Inverted Residuals and Linear Bottlenecks论文翻译——中英文对照
    
    </summary>
    
      <category term="深度学习" scheme="http://noahsnail.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="http://noahsnail.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>IO中同步、异步、阻塞、非阻塞的形象解释</title>
    <link href="http://noahsnail.com/2018/05/24/2018-05-24-IO%E4%B8%AD%E5%90%8C%E6%AD%A5%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E9%98%BB%E5%A1%9E%E3%80%81%E9%9D%9E%E9%98%BB%E5%A1%9E%E7%9A%84%E5%BD%A2%E8%B1%A1%E8%A7%A3%E9%87%8A/"/>
    <id>http://noahsnail.com/2018/05/24/2018-05-24-IO中同步、异步、阻塞、非阻塞的形象解释/</id>
    <published>2018-05-24T07:41:39.000Z</published>
    <updated>2018-05-24T07:42:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章作者：Tyan<br>博客：<a href="http://noahsnail.com">noahsnail.com</a> &nbsp;|&nbsp; <a href="http://blog.csdn.net/quincuntial" target="_blank" rel="external">CSDN</a> &nbsp;|&nbsp; <a href="http://www.jianshu.com/users/7731e83f3a4e/latest_articles" target="_blank" rel="external">简书</a></p>
<p><strong>注：以下文字来自网络，具体作者不知。</strong></p>
<p>老张爱喝茶，废话不说，煮开水。<br>出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。</p>
<ol>
<li>老张把水壶放到火上，立等水开。（同步阻塞）<br>老张觉得自己有点傻</li>
<li>老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞）<br>老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。</li>
<li>老张把响水壶放到火上，立等水开。（异步阻塞）<br>老张觉得这样傻等意义不大</li>
<li>老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞）<br>老张觉得自己聪明了。</li>
</ol>
<p>所谓同步异步，只是对于水壶而言。<br>普通水壶，同步；响水壶，异步。<br>虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。<br>同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。</p>
<p>所谓阻塞非阻塞，仅仅对于老张而言。<br>立等的老张，阻塞；看电视的老张，非阻塞。<br>情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。</p>
]]></content>
    
    <summary type="html">
    
      IO中同步、异步、阻塞、非阻塞的形象解释
    
    </summary>
    
      <category term="Python" scheme="http://noahsnail.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://noahsnail.com/tags/Python/"/>
    
  </entry>
  
</feed>
